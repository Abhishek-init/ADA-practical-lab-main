{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CO III  Neural_Network_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhishek-init/ADA-practical-lab-main/blob/main/CO_III_Neural_Network_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPEM4IUoDKA"
      },
      "source": [
        "# Joint Online Faculty Development programme on Deep Learning (Parallel Architecture) Aug 23 â€“ Sep 3 , 2021\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJe0cAaoG98"
      },
      "source": [
        "# Tutorial 3: Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIT7QrK2PwdM"
      },
      "source": [
        "Dataset: [Pima Indian Diabetes Dataset](https://data.world/data-society/pima-indians-diabetes-database#)\n",
        "\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
        "\n",
        "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "Attributes of PIMA dataset:\n",
        "\n",
        "**Pregnancies**: Number of times pregnant\n",
        "\n",
        "**Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness**: Triceps skin fold thickness (mm)\n",
        "\n",
        "**Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction**: Diabetes pedigree function\n",
        "\n",
        "**Age**: Age (years)\n",
        "\n",
        "**Outcome**: Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAgs3sTY712"
      },
      "source": [
        "**1. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrZg_G5MQ4L5",
        "outputId": "8fb4dd2f-fc80-44bf-96da-d9946d4ee88c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAhYoWHZAwg"
      },
      "source": [
        "**2. Move to the place where data resides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgG_3CiP4eQ",
        "outputId": "e53fa60e-4675-4387-b6de-2e51e070832c"
      },
      "source": [
        "%cd /content/drive/MyDrive"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S-KhHH_xATY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e560079-eccb-4332-a228-ac11eb2f6295"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Abhishek Singh Chauhan 0827CO191002 ADA.pdf'\n",
            "'Abhishek Singh Chauhan (1).pdf'\n",
            "'Alexa Skill'\n",
            " Certificates.pdf\n",
            " Classroom\n",
            "'CO-3yr-6th sem TT Feb 2022.pdf'\n",
            "'Covid 19 Pledge Abhishek Singh Chauhan.docx'\n",
            "'CSO Assignment CO-02 Abhishek.pdf'\n",
            " Cybersecurity_Foundation_Certificate_Abhishek.pdf\n",
            "'Cybersecurity_Foundation_Student_Certificate Rashida J.pdf'\n",
            "'Cyber Security Lab Analysis'\n",
            "'CyberSecurity Rashida Jawadwala'\n",
            " diabetes.csv\n",
            "'G22- Hotel Management System SRS (G-22).pdf'\n",
            " GDToT\n",
            "'Getting started.pdf'\n",
            " HackerRank_Python.pdf\n",
            " HackerRank_SQL_RESTAPI.pdf\n",
            "'MINOR PROJECT CO SECTION V SEM'\n",
            " Parent_AFD_2294594_2812202020494699.pdf\n",
            "'Shubhanshi Mahajan 0827CO191056.pdf'\n",
            " Student_AFD_2294594_28122020204945960.pdf\n",
            "'WhatsApp Image 2021-07-07 at 1.15.41 PM.jpeg'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f65jHMx2I_1O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvfswsOZLUB"
      },
      "source": [
        "**3. Read the dataset from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "32nNonRSSaQq",
        "outputId": "9bbb79a1-494f-4927-90b1-42b59adf3c99"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "data.head(10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b93a2161-c02e-42c2-980f-aad863f25f70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b93a2161-c02e-42c2-980f-aad863f25f70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b93a2161-c02e-42c2-980f-aad863f25f70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b93a2161-c02e-42c2-980f-aad863f25f70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrslDLESShr7",
        "outputId": "aea9d27e-69b6-4ddd-bf16-7cd1dae7684c"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLElehZ-Skgq",
        "outputId": "9082b431-fcab-4279-8b8b-e794a3c5d568"
      },
      "source": [
        "data.values"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnZxGc4ZQlf"
      },
      "source": [
        "**4. Store the data into input feature and label variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfA5BF0Sm4R",
        "outputId": "e044ba2c-0165-4de3-c301-6d49a23e102a"
      },
      "source": [
        "dataset= data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPZerNUZV4Q"
      },
      "source": [
        "**5. Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4g3T1fWri-",
        "outputId": "0c59f496-3260-4876-9a35-ebe21cfa47b6"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1B5x8C0ZY-e"
      },
      "source": [
        "**6. One-hot vector conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPUAnA-XNd8",
        "outputId": "2bf7faf9-ef5d-41b5-8368-e1d666284062"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJWmMxjZbgo"
      },
      "source": [
        "**7. Split the dataset into training, testing and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqXnV1FXYIV",
        "outputId": "16cefaec-55fa-4ea8-ae7c-4afebfb504a6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.2, random_state=10)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.2, random_state=10)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491\n",
            "154\n",
            "123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9IZizVZfKB"
      },
      "source": [
        "**8. Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNfmvbMOXeku",
        "outputId": "785874aa-23ec-4fc7-d762-c8075bb3d4fc"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(8, input_shape=(8,), activation='relu'))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_33 (Dense)            (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 10)                90        \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 184\n",
            "Trainable params: 184\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxZHI_EZiEF"
      },
      "source": [
        "**9. Model Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plF2qlxwXiIY"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.SGD(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VrUFVQZkNd"
      },
      "source": [
        "**10. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have 1000 training examples, and your batch size is  500, then it will take 2 iterations to complete 1 epoch."
      ],
      "metadata": {
        "id": "08Ul5lN90_Sp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDZ8yPhXrs0",
        "outputId": "6aa8f21c-ceda-4b4b-dc1e-42aed0c13773"
      },
      "source": [
        "hist = model.fit(X_training, Y_training,batch_size=4,  epochs=1000, validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "123/123 [==============================] - 1s 3ms/step - loss: 0.6815 - accuracy: 0.6680 - val_loss: 0.6854 - val_accuracy: 0.6179\n",
            "Epoch 2/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6748 - accuracy: 0.6680 - val_loss: 0.6815 - val_accuracy: 0.6260\n",
            "Epoch 3/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6695 - accuracy: 0.6680 - val_loss: 0.6784 - val_accuracy: 0.6260\n",
            "Epoch 4/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6651 - accuracy: 0.6680 - val_loss: 0.6759 - val_accuracy: 0.6260\n",
            "Epoch 5/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6614 - accuracy: 0.6680 - val_loss: 0.6741 - val_accuracy: 0.6260\n",
            "Epoch 6/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.6680 - val_loss: 0.6727 - val_accuracy: 0.6260\n",
            "Epoch 7/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6559 - accuracy: 0.6680 - val_loss: 0.6717 - val_accuracy: 0.6260\n",
            "Epoch 8/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.6680 - val_loss: 0.6709 - val_accuracy: 0.6260\n",
            "Epoch 9/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.6680 - val_loss: 0.6703 - val_accuracy: 0.6260\n",
            "Epoch 10/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6504 - accuracy: 0.6680 - val_loss: 0.6699 - val_accuracy: 0.6260\n",
            "Epoch 11/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6492 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 12/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6481 - accuracy: 0.6680 - val_loss: 0.6694 - val_accuracy: 0.6260\n",
            "Epoch 13/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6472 - accuracy: 0.6680 - val_loss: 0.6693 - val_accuracy: 0.6260\n",
            "Epoch 14/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6464 - accuracy: 0.6680 - val_loss: 0.6692 - val_accuracy: 0.6260\n",
            "Epoch 15/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6457 - accuracy: 0.6680 - val_loss: 0.6692 - val_accuracy: 0.6260\n",
            "Epoch 16/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6451 - accuracy: 0.6680 - val_loss: 0.6692 - val_accuracy: 0.6260\n",
            "Epoch 17/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6446 - accuracy: 0.6680 - val_loss: 0.6692 - val_accuracy: 0.6260\n",
            "Epoch 18/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6441 - accuracy: 0.6680 - val_loss: 0.6693 - val_accuracy: 0.6260\n",
            "Epoch 19/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6680 - val_loss: 0.6693 - val_accuracy: 0.6260\n",
            "Epoch 20/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6434 - accuracy: 0.6680 - val_loss: 0.6694 - val_accuracy: 0.6260\n",
            "Epoch 21/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6431 - accuracy: 0.6680 - val_loss: 0.6694 - val_accuracy: 0.6260\n",
            "Epoch 22/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.6680 - val_loss: 0.6695 - val_accuracy: 0.6260\n",
            "Epoch 23/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6426 - accuracy: 0.6680 - val_loss: 0.6695 - val_accuracy: 0.6260\n",
            "Epoch 24/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6423 - accuracy: 0.6680 - val_loss: 0.6695 - val_accuracy: 0.6260\n",
            "Epoch 25/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 26/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6419 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 27/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6417 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 28/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6415 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 29/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6413 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 30/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 31/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6410 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 32/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 33/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6407 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 34/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 35/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6405 - accuracy: 0.6680 - val_loss: 0.6696 - val_accuracy: 0.6260\n",
            "Epoch 36/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6403 - accuracy: 0.6680 - val_loss: 0.6695 - val_accuracy: 0.6260\n",
            "Epoch 37/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6680 - val_loss: 0.6695 - val_accuracy: 0.6260\n",
            "Epoch 38/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6401 - accuracy: 0.6680 - val_loss: 0.6695 - val_accuracy: 0.6260\n",
            "Epoch 39/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6400 - accuracy: 0.6680 - val_loss: 0.6694 - val_accuracy: 0.6260\n",
            "Epoch 40/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6399 - accuracy: 0.6680 - val_loss: 0.6694 - val_accuracy: 0.6260\n",
            "Epoch 41/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.6680 - val_loss: 0.6693 - val_accuracy: 0.6260\n",
            "Epoch 42/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6680 - val_loss: 0.6693 - val_accuracy: 0.6260\n",
            "Epoch 43/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6395 - accuracy: 0.6680 - val_loss: 0.6692 - val_accuracy: 0.6260\n",
            "Epoch 44/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6394 - accuracy: 0.6680 - val_loss: 0.6691 - val_accuracy: 0.6260\n",
            "Epoch 45/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6393 - accuracy: 0.6680 - val_loss: 0.6691 - val_accuracy: 0.6260\n",
            "Epoch 46/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6392 - accuracy: 0.6680 - val_loss: 0.6690 - val_accuracy: 0.6260\n",
            "Epoch 47/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6391 - accuracy: 0.6680 - val_loss: 0.6689 - val_accuracy: 0.6260\n",
            "Epoch 48/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.6680 - val_loss: 0.6689 - val_accuracy: 0.6260\n",
            "Epoch 49/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6389 - accuracy: 0.6680 - val_loss: 0.6688 - val_accuracy: 0.6260\n",
            "Epoch 50/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6388 - accuracy: 0.6680 - val_loss: 0.6687 - val_accuracy: 0.6260\n",
            "Epoch 51/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 0.6680 - val_loss: 0.6687 - val_accuracy: 0.6260\n",
            "Epoch 52/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6386 - accuracy: 0.6680 - val_loss: 0.6686 - val_accuracy: 0.6260\n",
            "Epoch 53/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.6680 - val_loss: 0.6686 - val_accuracy: 0.6260\n",
            "Epoch 54/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6384 - accuracy: 0.6680 - val_loss: 0.6685 - val_accuracy: 0.6260\n",
            "Epoch 55/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6383 - accuracy: 0.6680 - val_loss: 0.6685 - val_accuracy: 0.6260\n",
            "Epoch 56/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.6680 - val_loss: 0.6685 - val_accuracy: 0.6260\n",
            "Epoch 57/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6381 - accuracy: 0.6680 - val_loss: 0.6684 - val_accuracy: 0.6260\n",
            "Epoch 58/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6381 - accuracy: 0.6680 - val_loss: 0.6684 - val_accuracy: 0.6260\n",
            "Epoch 59/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.6680 - val_loss: 0.6683 - val_accuracy: 0.6260\n",
            "Epoch 60/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6379 - accuracy: 0.6680 - val_loss: 0.6683 - val_accuracy: 0.6260\n",
            "Epoch 61/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6378 - accuracy: 0.6680 - val_loss: 0.6682 - val_accuracy: 0.6260\n",
            "Epoch 62/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6377 - accuracy: 0.6680 - val_loss: 0.6682 - val_accuracy: 0.6260\n",
            "Epoch 63/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.6680 - val_loss: 0.6681 - val_accuracy: 0.6260\n",
            "Epoch 64/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6376 - accuracy: 0.6680 - val_loss: 0.6680 - val_accuracy: 0.6260\n",
            "Epoch 65/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6680 - val_loss: 0.6680 - val_accuracy: 0.6260\n",
            "Epoch 66/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6374 - accuracy: 0.6680 - val_loss: 0.6679 - val_accuracy: 0.6260\n",
            "Epoch 67/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.6680 - val_loss: 0.6678 - val_accuracy: 0.6260\n",
            "Epoch 68/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6372 - accuracy: 0.6680 - val_loss: 0.6677 - val_accuracy: 0.6260\n",
            "Epoch 69/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6372 - accuracy: 0.6680 - val_loss: 0.6677 - val_accuracy: 0.6260\n",
            "Epoch 70/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6371 - accuracy: 0.6680 - val_loss: 0.6676 - val_accuracy: 0.6260\n",
            "Epoch 71/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6370 - accuracy: 0.6680 - val_loss: 0.6675 - val_accuracy: 0.6260\n",
            "Epoch 72/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6369 - accuracy: 0.6680 - val_loss: 0.6675 - val_accuracy: 0.6260\n",
            "Epoch 73/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6368 - accuracy: 0.6680 - val_loss: 0.6674 - val_accuracy: 0.6260\n",
            "Epoch 74/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.6680 - val_loss: 0.6673 - val_accuracy: 0.6260\n",
            "Epoch 75/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6680 - val_loss: 0.6672 - val_accuracy: 0.6260\n",
            "Epoch 76/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.6680 - val_loss: 0.6672 - val_accuracy: 0.6260\n",
            "Epoch 77/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.6680 - val_loss: 0.6671 - val_accuracy: 0.6260\n",
            "Epoch 78/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6365 - accuracy: 0.6680 - val_loss: 0.6670 - val_accuracy: 0.6260\n",
            "Epoch 79/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6364 - accuracy: 0.6680 - val_loss: 0.6670 - val_accuracy: 0.6260\n",
            "Epoch 80/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6363 - accuracy: 0.6680 - val_loss: 0.6669 - val_accuracy: 0.6260\n",
            "Epoch 81/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6362 - accuracy: 0.6680 - val_loss: 0.6668 - val_accuracy: 0.6260\n",
            "Epoch 82/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6680 - val_loss: 0.6667 - val_accuracy: 0.6260\n",
            "Epoch 83/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6361 - accuracy: 0.6680 - val_loss: 0.6666 - val_accuracy: 0.6260\n",
            "Epoch 84/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6359 - accuracy: 0.6680 - val_loss: 0.6665 - val_accuracy: 0.6260\n",
            "Epoch 85/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6358 - accuracy: 0.6680 - val_loss: 0.6664 - val_accuracy: 0.6260\n",
            "Epoch 86/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6358 - accuracy: 0.6680 - val_loss: 0.6663 - val_accuracy: 0.6260\n",
            "Epoch 87/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.6680 - val_loss: 0.6662 - val_accuracy: 0.6260\n",
            "Epoch 88/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6355 - accuracy: 0.6680 - val_loss: 0.6661 - val_accuracy: 0.6260\n",
            "Epoch 89/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6354 - accuracy: 0.6680 - val_loss: 0.6660 - val_accuracy: 0.6260\n",
            "Epoch 90/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6353 - accuracy: 0.6680 - val_loss: 0.6659 - val_accuracy: 0.6260\n",
            "Epoch 91/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.6680 - val_loss: 0.6658 - val_accuracy: 0.6260\n",
            "Epoch 92/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6351 - accuracy: 0.6680 - val_loss: 0.6657 - val_accuracy: 0.6260\n",
            "Epoch 93/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6680 - val_loss: 0.6656 - val_accuracy: 0.6260\n",
            "Epoch 94/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6349 - accuracy: 0.6680 - val_loss: 0.6655 - val_accuracy: 0.6260\n",
            "Epoch 95/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.6680 - val_loss: 0.6654 - val_accuracy: 0.6260\n",
            "Epoch 96/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6346 - accuracy: 0.6680 - val_loss: 0.6653 - val_accuracy: 0.6260\n",
            "Epoch 97/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6680 - val_loss: 0.6652 - val_accuracy: 0.6260\n",
            "Epoch 98/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6344 - accuracy: 0.6680 - val_loss: 0.6651 - val_accuracy: 0.6260\n",
            "Epoch 99/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6343 - accuracy: 0.6680 - val_loss: 0.6649 - val_accuracy: 0.6260\n",
            "Epoch 100/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6680 - val_loss: 0.6648 - val_accuracy: 0.6260\n",
            "Epoch 101/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6340 - accuracy: 0.6680 - val_loss: 0.6647 - val_accuracy: 0.6260\n",
            "Epoch 102/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6339 - accuracy: 0.6680 - val_loss: 0.6647 - val_accuracy: 0.6260\n",
            "Epoch 103/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.6680 - val_loss: 0.6646 - val_accuracy: 0.6260\n",
            "Epoch 104/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6337 - accuracy: 0.6680 - val_loss: 0.6645 - val_accuracy: 0.6260\n",
            "Epoch 105/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6336 - accuracy: 0.6680 - val_loss: 0.6644 - val_accuracy: 0.6260\n",
            "Epoch 106/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.6680 - val_loss: 0.6643 - val_accuracy: 0.6260\n",
            "Epoch 107/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6334 - accuracy: 0.6680 - val_loss: 0.6642 - val_accuracy: 0.6260\n",
            "Epoch 108/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.6680 - val_loss: 0.6640 - val_accuracy: 0.6260\n",
            "Epoch 109/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.6680 - val_loss: 0.6639 - val_accuracy: 0.6260\n",
            "Epoch 110/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.6680 - val_loss: 0.6639 - val_accuracy: 0.6260\n",
            "Epoch 111/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6329 - accuracy: 0.6680 - val_loss: 0.6637 - val_accuracy: 0.6260\n",
            "Epoch 112/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.6680 - val_loss: 0.6637 - val_accuracy: 0.6260\n",
            "Epoch 113/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6328 - accuracy: 0.6680 - val_loss: 0.6636 - val_accuracy: 0.6260\n",
            "Epoch 114/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6326 - accuracy: 0.6680 - val_loss: 0.6636 - val_accuracy: 0.6260\n",
            "Epoch 115/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6326 - accuracy: 0.6680 - val_loss: 0.6635 - val_accuracy: 0.6260\n",
            "Epoch 116/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6325 - accuracy: 0.6680 - val_loss: 0.6635 - val_accuracy: 0.6260\n",
            "Epoch 117/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6324 - accuracy: 0.6680 - val_loss: 0.6634 - val_accuracy: 0.6260\n",
            "Epoch 118/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6324 - accuracy: 0.6680 - val_loss: 0.6634 - val_accuracy: 0.6260\n",
            "Epoch 119/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6323 - accuracy: 0.6680 - val_loss: 0.6633 - val_accuracy: 0.6260\n",
            "Epoch 120/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6322 - accuracy: 0.6680 - val_loss: 0.6632 - val_accuracy: 0.6260\n",
            "Epoch 121/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6321 - accuracy: 0.6680 - val_loss: 0.6631 - val_accuracy: 0.6260\n",
            "Epoch 122/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6320 - accuracy: 0.6680 - val_loss: 0.6631 - val_accuracy: 0.6260\n",
            "Epoch 123/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6320 - accuracy: 0.6680 - val_loss: 0.6630 - val_accuracy: 0.6260\n",
            "Epoch 124/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6319 - accuracy: 0.6680 - val_loss: 0.6629 - val_accuracy: 0.6260\n",
            "Epoch 125/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.6680 - val_loss: 0.6629 - val_accuracy: 0.6260\n",
            "Epoch 126/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.6680 - val_loss: 0.6628 - val_accuracy: 0.6260\n",
            "Epoch 127/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.6680 - val_loss: 0.6627 - val_accuracy: 0.6260\n",
            "Epoch 128/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6316 - accuracy: 0.6680 - val_loss: 0.6626 - val_accuracy: 0.6260\n",
            "Epoch 129/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.6680 - val_loss: 0.6625 - val_accuracy: 0.6260\n",
            "Epoch 130/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.6680 - val_loss: 0.6624 - val_accuracy: 0.6260\n",
            "Epoch 131/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.6680 - val_loss: 0.6624 - val_accuracy: 0.6260\n",
            "Epoch 132/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.6680 - val_loss: 0.6623 - val_accuracy: 0.6260\n",
            "Epoch 133/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6312 - accuracy: 0.6680 - val_loss: 0.6622 - val_accuracy: 0.6260\n",
            "Epoch 134/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6311 - accuracy: 0.6680 - val_loss: 0.6621 - val_accuracy: 0.6260\n",
            "Epoch 135/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6310 - accuracy: 0.6680 - val_loss: 0.6620 - val_accuracy: 0.6260\n",
            "Epoch 136/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6309 - accuracy: 0.6680 - val_loss: 0.6620 - val_accuracy: 0.6260\n",
            "Epoch 137/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6308 - accuracy: 0.6680 - val_loss: 0.6619 - val_accuracy: 0.6260\n",
            "Epoch 138/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6308 - accuracy: 0.6680 - val_loss: 0.6618 - val_accuracy: 0.6260\n",
            "Epoch 139/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6307 - accuracy: 0.6680 - val_loss: 0.6617 - val_accuracy: 0.6260\n",
            "Epoch 140/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6306 - accuracy: 0.6680 - val_loss: 0.6616 - val_accuracy: 0.6260\n",
            "Epoch 141/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.6680 - val_loss: 0.6615 - val_accuracy: 0.6260\n",
            "Epoch 142/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6304 - accuracy: 0.6680 - val_loss: 0.6614 - val_accuracy: 0.6260\n",
            "Epoch 143/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6304 - accuracy: 0.6680 - val_loss: 0.6613 - val_accuracy: 0.6260\n",
            "Epoch 144/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6303 - accuracy: 0.6680 - val_loss: 0.6612 - val_accuracy: 0.6260\n",
            "Epoch 145/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.6680 - val_loss: 0.6611 - val_accuracy: 0.6260\n",
            "Epoch 146/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6301 - accuracy: 0.6680 - val_loss: 0.6610 - val_accuracy: 0.6260\n",
            "Epoch 147/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6300 - accuracy: 0.6680 - val_loss: 0.6609 - val_accuracy: 0.6260\n",
            "Epoch 148/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.6680 - val_loss: 0.6608 - val_accuracy: 0.6260\n",
            "Epoch 149/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.6680 - val_loss: 0.6607 - val_accuracy: 0.6260\n",
            "Epoch 150/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6298 - accuracy: 0.6680 - val_loss: 0.6606 - val_accuracy: 0.6260\n",
            "Epoch 151/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.6680 - val_loss: 0.6605 - val_accuracy: 0.6260\n",
            "Epoch 152/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.6680 - val_loss: 0.6604 - val_accuracy: 0.6260\n",
            "Epoch 153/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6295 - accuracy: 0.6680 - val_loss: 0.6602 - val_accuracy: 0.6260\n",
            "Epoch 154/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6294 - accuracy: 0.6680 - val_loss: 0.6601 - val_accuracy: 0.6260\n",
            "Epoch 155/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.6680 - val_loss: 0.6600 - val_accuracy: 0.6260\n",
            "Epoch 156/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6292 - accuracy: 0.6680 - val_loss: 0.6598 - val_accuracy: 0.6260\n",
            "Epoch 157/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6291 - accuracy: 0.6680 - val_loss: 0.6597 - val_accuracy: 0.6260\n",
            "Epoch 158/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.6680 - val_loss: 0.6595 - val_accuracy: 0.6260\n",
            "Epoch 159/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6289 - accuracy: 0.6680 - val_loss: 0.6594 - val_accuracy: 0.6260\n",
            "Epoch 160/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6680 - val_loss: 0.6593 - val_accuracy: 0.6260\n",
            "Epoch 161/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6287 - accuracy: 0.6680 - val_loss: 0.6591 - val_accuracy: 0.6260\n",
            "Epoch 162/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6285 - accuracy: 0.6680 - val_loss: 0.6589 - val_accuracy: 0.6260\n",
            "Epoch 163/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6284 - accuracy: 0.6680 - val_loss: 0.6587 - val_accuracy: 0.6260\n",
            "Epoch 164/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.6680 - val_loss: 0.6585 - val_accuracy: 0.6260\n",
            "Epoch 165/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6282 - accuracy: 0.6680 - val_loss: 0.6583 - val_accuracy: 0.6260\n",
            "Epoch 166/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6280 - accuracy: 0.6680 - val_loss: 0.6581 - val_accuracy: 0.6260\n",
            "Epoch 167/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6279 - accuracy: 0.6680 - val_loss: 0.6579 - val_accuracy: 0.6260\n",
            "Epoch 168/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.6680 - val_loss: 0.6576 - val_accuracy: 0.6260\n",
            "Epoch 169/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6276 - accuracy: 0.6680 - val_loss: 0.6573 - val_accuracy: 0.6260\n",
            "Epoch 170/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6274 - accuracy: 0.6680 - val_loss: 0.6570 - val_accuracy: 0.6260\n",
            "Epoch 171/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6680 - val_loss: 0.6567 - val_accuracy: 0.6260\n",
            "Epoch 172/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6271 - accuracy: 0.6680 - val_loss: 0.6565 - val_accuracy: 0.6260\n",
            "Epoch 173/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6680 - val_loss: 0.6563 - val_accuracy: 0.6260\n",
            "Epoch 174/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.6680 - val_loss: 0.6560 - val_accuracy: 0.6260\n",
            "Epoch 175/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.6680 - val_loss: 0.6558 - val_accuracy: 0.6260\n",
            "Epoch 176/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6680 - val_loss: 0.6556 - val_accuracy: 0.6260\n",
            "Epoch 177/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6263 - accuracy: 0.6680 - val_loss: 0.6554 - val_accuracy: 0.6260\n",
            "Epoch 178/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.6680 - val_loss: 0.6551 - val_accuracy: 0.6260\n",
            "Epoch 179/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.6680 - val_loss: 0.6549 - val_accuracy: 0.6260\n",
            "Epoch 180/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6680 - val_loss: 0.6547 - val_accuracy: 0.6260\n",
            "Epoch 181/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6680 - val_loss: 0.6544 - val_accuracy: 0.6260\n",
            "Epoch 182/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6255 - accuracy: 0.6680 - val_loss: 0.6541 - val_accuracy: 0.6260\n",
            "Epoch 183/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.6680 - val_loss: 0.6538 - val_accuracy: 0.6260\n",
            "Epoch 184/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.6680 - val_loss: 0.6534 - val_accuracy: 0.6260\n",
            "Epoch 185/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.6680 - val_loss: 0.6530 - val_accuracy: 0.6260\n",
            "Epoch 186/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6247 - accuracy: 0.6680 - val_loss: 0.6527 - val_accuracy: 0.6260\n",
            "Epoch 187/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6244 - accuracy: 0.6680 - val_loss: 0.6523 - val_accuracy: 0.6260\n",
            "Epoch 188/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6242 - accuracy: 0.6680 - val_loss: 0.6520 - val_accuracy: 0.6260\n",
            "Epoch 189/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6240 - accuracy: 0.6680 - val_loss: 0.6516 - val_accuracy: 0.6260\n",
            "Epoch 190/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6238 - accuracy: 0.6680 - val_loss: 0.6512 - val_accuracy: 0.6260\n",
            "Epoch 191/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.6680 - val_loss: 0.6507 - val_accuracy: 0.6260\n",
            "Epoch 192/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.6680 - val_loss: 0.6502 - val_accuracy: 0.6260\n",
            "Epoch 193/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6229 - accuracy: 0.6680 - val_loss: 0.6497 - val_accuracy: 0.6260\n",
            "Epoch 194/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.6680 - val_loss: 0.6491 - val_accuracy: 0.6260\n",
            "Epoch 195/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6680 - val_loss: 0.6486 - val_accuracy: 0.6260\n",
            "Epoch 196/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.6680 - val_loss: 0.6481 - val_accuracy: 0.6260\n",
            "Epoch 197/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.6680 - val_loss: 0.6475 - val_accuracy: 0.6260\n",
            "Epoch 198/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6215 - accuracy: 0.6660 - val_loss: 0.6471 - val_accuracy: 0.6260\n",
            "Epoch 199/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.6660 - val_loss: 0.6465 - val_accuracy: 0.6260\n",
            "Epoch 200/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6208 - accuracy: 0.6660 - val_loss: 0.6460 - val_accuracy: 0.6260\n",
            "Epoch 201/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6204 - accuracy: 0.6660 - val_loss: 0.6453 - val_accuracy: 0.6260\n",
            "Epoch 202/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6201 - accuracy: 0.6660 - val_loss: 0.6447 - val_accuracy: 0.6260\n",
            "Epoch 203/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6198 - accuracy: 0.6660 - val_loss: 0.6441 - val_accuracy: 0.6260\n",
            "Epoch 204/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.6660 - val_loss: 0.6436 - val_accuracy: 0.6260\n",
            "Epoch 205/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6191 - accuracy: 0.6660 - val_loss: 0.6431 - val_accuracy: 0.6260\n",
            "Epoch 206/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6187 - accuracy: 0.6660 - val_loss: 0.6425 - val_accuracy: 0.6260\n",
            "Epoch 207/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.6660 - val_loss: 0.6418 - val_accuracy: 0.6260\n",
            "Epoch 208/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.6660 - val_loss: 0.6412 - val_accuracy: 0.6260\n",
            "Epoch 209/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6175 - accuracy: 0.6660 - val_loss: 0.6405 - val_accuracy: 0.6260\n",
            "Epoch 210/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6171 - accuracy: 0.6660 - val_loss: 0.6398 - val_accuracy: 0.6260\n",
            "Epoch 211/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6166 - accuracy: 0.6660 - val_loss: 0.6391 - val_accuracy: 0.6260\n",
            "Epoch 212/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6162 - accuracy: 0.6660 - val_loss: 0.6383 - val_accuracy: 0.6260\n",
            "Epoch 213/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.6660 - val_loss: 0.6376 - val_accuracy: 0.6260\n",
            "Epoch 214/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6154 - accuracy: 0.6660 - val_loss: 0.6369 - val_accuracy: 0.6260\n",
            "Epoch 215/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.6660 - val_loss: 0.6363 - val_accuracy: 0.6260\n",
            "Epoch 216/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.6660 - val_loss: 0.6355 - val_accuracy: 0.6260\n",
            "Epoch 217/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6138 - accuracy: 0.6660 - val_loss: 0.6347 - val_accuracy: 0.6260\n",
            "Epoch 218/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6134 - accuracy: 0.6660 - val_loss: 0.6340 - val_accuracy: 0.6260\n",
            "Epoch 219/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6128 - accuracy: 0.6660 - val_loss: 0.6333 - val_accuracy: 0.6341\n",
            "Epoch 220/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6123 - accuracy: 0.6660 - val_loss: 0.6326 - val_accuracy: 0.6341\n",
            "Epoch 221/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6118 - accuracy: 0.6660 - val_loss: 0.6318 - val_accuracy: 0.6341\n",
            "Epoch 222/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6113 - accuracy: 0.6680 - val_loss: 0.6311 - val_accuracy: 0.6341\n",
            "Epoch 223/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6107 - accuracy: 0.6680 - val_loss: 0.6304 - val_accuracy: 0.6341\n",
            "Epoch 224/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6102 - accuracy: 0.6701 - val_loss: 0.6298 - val_accuracy: 0.6423\n",
            "Epoch 225/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6096 - accuracy: 0.6721 - val_loss: 0.6289 - val_accuracy: 0.6423\n",
            "Epoch 226/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6090 - accuracy: 0.6680 - val_loss: 0.6280 - val_accuracy: 0.6423\n",
            "Epoch 227/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6701 - val_loss: 0.6272 - val_accuracy: 0.6423\n",
            "Epoch 228/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6079 - accuracy: 0.6701 - val_loss: 0.6265 - val_accuracy: 0.6423\n",
            "Epoch 229/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6073 - accuracy: 0.6701 - val_loss: 0.6256 - val_accuracy: 0.6423\n",
            "Epoch 230/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6067 - accuracy: 0.6701 - val_loss: 0.6249 - val_accuracy: 0.6423\n",
            "Epoch 231/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6701 - val_loss: 0.6243 - val_accuracy: 0.6423\n",
            "Epoch 232/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6055 - accuracy: 0.6701 - val_loss: 0.6235 - val_accuracy: 0.6423\n",
            "Epoch 233/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.6701 - val_loss: 0.6228 - val_accuracy: 0.6423\n",
            "Epoch 234/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6043 - accuracy: 0.6701 - val_loss: 0.6221 - val_accuracy: 0.6423\n",
            "Epoch 235/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6036 - accuracy: 0.6701 - val_loss: 0.6213 - val_accuracy: 0.6423\n",
            "Epoch 236/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6029 - accuracy: 0.6701 - val_loss: 0.6207 - val_accuracy: 0.6423\n",
            "Epoch 237/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.6701 - val_loss: 0.6199 - val_accuracy: 0.6423\n",
            "Epoch 238/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6017 - accuracy: 0.6701 - val_loss: 0.6191 - val_accuracy: 0.6423\n",
            "Epoch 239/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.6701 - val_loss: 0.6184 - val_accuracy: 0.6423\n",
            "Epoch 240/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.6004 - accuracy: 0.6701 - val_loss: 0.6176 - val_accuracy: 0.6423\n",
            "Epoch 241/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5998 - accuracy: 0.6701 - val_loss: 0.6169 - val_accuracy: 0.6423\n",
            "Epoch 242/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6721 - val_loss: 0.6161 - val_accuracy: 0.6423\n",
            "Epoch 243/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5985 - accuracy: 0.6762 - val_loss: 0.6152 - val_accuracy: 0.6504\n",
            "Epoch 244/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5978 - accuracy: 0.6782 - val_loss: 0.6145 - val_accuracy: 0.6504\n",
            "Epoch 245/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5971 - accuracy: 0.6762 - val_loss: 0.6137 - val_accuracy: 0.6504\n",
            "Epoch 246/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5964 - accuracy: 0.6802 - val_loss: 0.6130 - val_accuracy: 0.6504\n",
            "Epoch 247/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6802 - val_loss: 0.6119 - val_accuracy: 0.6504\n",
            "Epoch 248/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5951 - accuracy: 0.6823 - val_loss: 0.6110 - val_accuracy: 0.6504\n",
            "Epoch 249/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5944 - accuracy: 0.6782 - val_loss: 0.6101 - val_accuracy: 0.6504\n",
            "Epoch 250/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5937 - accuracy: 0.6823 - val_loss: 0.6091 - val_accuracy: 0.6504\n",
            "Epoch 251/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5930 - accuracy: 0.6864 - val_loss: 0.6084 - val_accuracy: 0.6504\n",
            "Epoch 252/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6823 - val_loss: 0.6075 - val_accuracy: 0.6504\n",
            "Epoch 253/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.6843 - val_loss: 0.6066 - val_accuracy: 0.6504\n",
            "Epoch 254/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.6864 - val_loss: 0.6057 - val_accuracy: 0.6504\n",
            "Epoch 255/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6864 - val_loss: 0.6047 - val_accuracy: 0.6504\n",
            "Epoch 256/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6884 - val_loss: 0.6037 - val_accuracy: 0.6504\n",
            "Epoch 257/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.6904 - val_loss: 0.6030 - val_accuracy: 0.6504\n",
            "Epoch 258/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.6864 - val_loss: 0.6018 - val_accuracy: 0.6504\n",
            "Epoch 259/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6904 - val_loss: 0.6009 - val_accuracy: 0.6504\n",
            "Epoch 260/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5864 - accuracy: 0.6904 - val_loss: 0.5999 - val_accuracy: 0.6504\n",
            "Epoch 261/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.6904 - val_loss: 0.5989 - val_accuracy: 0.6504\n",
            "Epoch 262/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.6904 - val_loss: 0.5981 - val_accuracy: 0.6504\n",
            "Epoch 263/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5840 - accuracy: 0.6904 - val_loss: 0.5972 - val_accuracy: 0.6504\n",
            "Epoch 264/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5832 - accuracy: 0.6884 - val_loss: 0.5964 - val_accuracy: 0.6504\n",
            "Epoch 265/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5825 - accuracy: 0.6904 - val_loss: 0.5953 - val_accuracy: 0.6504\n",
            "Epoch 266/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5817 - accuracy: 0.6925 - val_loss: 0.5943 - val_accuracy: 0.6504\n",
            "Epoch 267/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5809 - accuracy: 0.6904 - val_loss: 0.5931 - val_accuracy: 0.6504\n",
            "Epoch 268/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.6904 - val_loss: 0.5921 - val_accuracy: 0.6504\n",
            "Epoch 269/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5792 - accuracy: 0.6945 - val_loss: 0.5912 - val_accuracy: 0.6504\n",
            "Epoch 270/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5784 - accuracy: 0.6904 - val_loss: 0.5901 - val_accuracy: 0.6585\n",
            "Epoch 271/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.6925 - val_loss: 0.5890 - val_accuracy: 0.6585\n",
            "Epoch 272/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5767 - accuracy: 0.6945 - val_loss: 0.5879 - val_accuracy: 0.6585\n",
            "Epoch 273/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5758 - accuracy: 0.6986 - val_loss: 0.5868 - val_accuracy: 0.6667\n",
            "Epoch 274/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5750 - accuracy: 0.6986 - val_loss: 0.5855 - val_accuracy: 0.6667\n",
            "Epoch 275/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5741 - accuracy: 0.7006 - val_loss: 0.5843 - val_accuracy: 0.6748\n",
            "Epoch 276/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5732 - accuracy: 0.7006 - val_loss: 0.5834 - val_accuracy: 0.6748\n",
            "Epoch 277/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.6986 - val_loss: 0.5822 - val_accuracy: 0.6829\n",
            "Epoch 278/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.7006 - val_loss: 0.5811 - val_accuracy: 0.6829\n",
            "Epoch 279/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.6986 - val_loss: 0.5801 - val_accuracy: 0.6829\n",
            "Epoch 280/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.7026 - val_loss: 0.5789 - val_accuracy: 0.6911\n",
            "Epoch 281/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7006 - val_loss: 0.5778 - val_accuracy: 0.6992\n",
            "Epoch 282/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7006 - val_loss: 0.5767 - val_accuracy: 0.6992\n",
            "Epoch 283/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5669 - accuracy: 0.7047 - val_loss: 0.5756 - val_accuracy: 0.6992\n",
            "Epoch 284/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5660 - accuracy: 0.7006 - val_loss: 0.5746 - val_accuracy: 0.6911\n",
            "Epoch 285/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5650 - accuracy: 0.7047 - val_loss: 0.5736 - val_accuracy: 0.6911\n",
            "Epoch 286/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7047 - val_loss: 0.5722 - val_accuracy: 0.6911\n",
            "Epoch 287/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7047 - val_loss: 0.5710 - val_accuracy: 0.6911\n",
            "Epoch 288/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7026 - val_loss: 0.5697 - val_accuracy: 0.6911\n",
            "Epoch 289/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5613 - accuracy: 0.7088 - val_loss: 0.5687 - val_accuracy: 0.6992\n",
            "Epoch 290/1000\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.5603 - accuracy: 0.7026 - val_loss: 0.5675 - val_accuracy: 0.6992\n",
            "Epoch 291/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7047 - val_loss: 0.5665 - val_accuracy: 0.6992\n",
            "Epoch 292/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5585 - accuracy: 0.7067 - val_loss: 0.5653 - val_accuracy: 0.6911\n",
            "Epoch 293/1000\n",
            "123/123 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.7088 - val_loss: 0.5644 - val_accuracy: 0.6911\n",
            "Epoch 294/1000\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 0.5566 - accuracy: 0.7067 - val_loss: 0.5631 - val_accuracy: 0.7073\n",
            "Epoch 295/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5556 - accuracy: 0.7108 - val_loss: 0.5620 - val_accuracy: 0.7073\n",
            "Epoch 296/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7189 - val_loss: 0.5610 - val_accuracy: 0.7073\n",
            "Epoch 297/1000\n",
            "123/123 [==============================] - 1s 5ms/step - loss: 0.5537 - accuracy: 0.7108 - val_loss: 0.5599 - val_accuracy: 0.7073\n",
            "Epoch 298/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5528 - accuracy: 0.7128 - val_loss: 0.5587 - val_accuracy: 0.7073\n",
            "Epoch 299/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5518 - accuracy: 0.7169 - val_loss: 0.5576 - val_accuracy: 0.7073\n",
            "Epoch 300/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7189 - val_loss: 0.5564 - val_accuracy: 0.7154\n",
            "Epoch 301/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7149 - val_loss: 0.5549 - val_accuracy: 0.7154\n",
            "Epoch 302/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7251 - val_loss: 0.5543 - val_accuracy: 0.7154\n",
            "Epoch 303/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7210 - val_loss: 0.5527 - val_accuracy: 0.7154\n",
            "Epoch 304/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5471 - accuracy: 0.7230 - val_loss: 0.5518 - val_accuracy: 0.7154\n",
            "Epoch 305/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7230 - val_loss: 0.5506 - val_accuracy: 0.7154\n",
            "Epoch 306/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5452 - accuracy: 0.7210 - val_loss: 0.5497 - val_accuracy: 0.7154\n",
            "Epoch 307/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7210 - val_loss: 0.5486 - val_accuracy: 0.7154\n",
            "Epoch 308/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5433 - accuracy: 0.7210 - val_loss: 0.5475 - val_accuracy: 0.7154\n",
            "Epoch 309/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7251 - val_loss: 0.5463 - val_accuracy: 0.7236\n",
            "Epoch 310/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7251 - val_loss: 0.5449 - val_accuracy: 0.7317\n",
            "Epoch 311/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7210 - val_loss: 0.5436 - val_accuracy: 0.7317\n",
            "Epoch 312/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5395 - accuracy: 0.7291 - val_loss: 0.5429 - val_accuracy: 0.7317\n",
            "Epoch 313/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7271 - val_loss: 0.5414 - val_accuracy: 0.7317\n",
            "Epoch 314/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5379 - accuracy: 0.7291 - val_loss: 0.5405 - val_accuracy: 0.7317\n",
            "Epoch 315/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7291 - val_loss: 0.5394 - val_accuracy: 0.7317\n",
            "Epoch 316/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5361 - accuracy: 0.7271 - val_loss: 0.5383 - val_accuracy: 0.7317\n",
            "Epoch 317/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7332 - val_loss: 0.5376 - val_accuracy: 0.7317\n",
            "Epoch 318/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5343 - accuracy: 0.7332 - val_loss: 0.5366 - val_accuracy: 0.7398\n",
            "Epoch 319/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7332 - val_loss: 0.5354 - val_accuracy: 0.7398\n",
            "Epoch 320/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7312 - val_loss: 0.5345 - val_accuracy: 0.7398\n",
            "Epoch 321/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7332 - val_loss: 0.5333 - val_accuracy: 0.7398\n",
            "Epoch 322/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5307 - accuracy: 0.7332 - val_loss: 0.5322 - val_accuracy: 0.7398\n",
            "Epoch 323/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5299 - accuracy: 0.7352 - val_loss: 0.5310 - val_accuracy: 0.7480\n",
            "Epoch 324/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5290 - accuracy: 0.7475 - val_loss: 0.5301 - val_accuracy: 0.7480\n",
            "Epoch 325/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5282 - accuracy: 0.7454 - val_loss: 0.5291 - val_accuracy: 0.7480\n",
            "Epoch 326/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5273 - accuracy: 0.7495 - val_loss: 0.5282 - val_accuracy: 0.7480\n",
            "Epoch 327/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.7475 - val_loss: 0.5273 - val_accuracy: 0.7480\n",
            "Epoch 328/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.7434 - val_loss: 0.5259 - val_accuracy: 0.7561\n",
            "Epoch 329/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5249 - accuracy: 0.7536 - val_loss: 0.5253 - val_accuracy: 0.7561\n",
            "Epoch 330/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5241 - accuracy: 0.7536 - val_loss: 0.5244 - val_accuracy: 0.7561\n",
            "Epoch 331/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7515 - val_loss: 0.5231 - val_accuracy: 0.7561\n",
            "Epoch 332/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7536 - val_loss: 0.5224 - val_accuracy: 0.7561\n",
            "Epoch 333/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5217 - accuracy: 0.7556 - val_loss: 0.5214 - val_accuracy: 0.7561\n",
            "Epoch 334/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7515 - val_loss: 0.5204 - val_accuracy: 0.7561\n",
            "Epoch 335/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5202 - accuracy: 0.7515 - val_loss: 0.5195 - val_accuracy: 0.7480\n",
            "Epoch 336/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5193 - accuracy: 0.7597 - val_loss: 0.5188 - val_accuracy: 0.7561\n",
            "Epoch 337/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5186 - accuracy: 0.7536 - val_loss: 0.5178 - val_accuracy: 0.7480\n",
            "Epoch 338/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5179 - accuracy: 0.7576 - val_loss: 0.5170 - val_accuracy: 0.7480\n",
            "Epoch 339/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5170 - accuracy: 0.7658 - val_loss: 0.5163 - val_accuracy: 0.7480\n",
            "Epoch 340/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7637 - val_loss: 0.5157 - val_accuracy: 0.7480\n",
            "Epoch 341/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5156 - accuracy: 0.7597 - val_loss: 0.5148 - val_accuracy: 0.7480\n",
            "Epoch 342/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5149 - accuracy: 0.7637 - val_loss: 0.5141 - val_accuracy: 0.7480\n",
            "Epoch 343/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.7658 - val_loss: 0.5133 - val_accuracy: 0.7480\n",
            "Epoch 344/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.7597 - val_loss: 0.5128 - val_accuracy: 0.7480\n",
            "Epoch 345/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5129 - accuracy: 0.7658 - val_loss: 0.5118 - val_accuracy: 0.7480\n",
            "Epoch 346/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5122 - accuracy: 0.7637 - val_loss: 0.5109 - val_accuracy: 0.7480\n",
            "Epoch 347/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5116 - accuracy: 0.7658 - val_loss: 0.5105 - val_accuracy: 0.7480\n",
            "Epoch 348/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7617 - val_loss: 0.5092 - val_accuracy: 0.7642\n",
            "Epoch 349/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.7576 - val_loss: 0.5084 - val_accuracy: 0.7724\n",
            "Epoch 350/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.7597 - val_loss: 0.5079 - val_accuracy: 0.7724\n",
            "Epoch 351/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.7617 - val_loss: 0.5070 - val_accuracy: 0.7724\n",
            "Epoch 352/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5085 - accuracy: 0.7637 - val_loss: 0.5067 - val_accuracy: 0.7642\n",
            "Epoch 353/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5079 - accuracy: 0.7576 - val_loss: 0.5059 - val_accuracy: 0.7724\n",
            "Epoch 354/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.7597 - val_loss: 0.5049 - val_accuracy: 0.7724\n",
            "Epoch 355/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5067 - accuracy: 0.7617 - val_loss: 0.5043 - val_accuracy: 0.7724\n",
            "Epoch 356/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7637 - val_loss: 0.5034 - val_accuracy: 0.7724\n",
            "Epoch 357/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5055 - accuracy: 0.7637 - val_loss: 0.5033 - val_accuracy: 0.7724\n",
            "Epoch 358/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.7597 - val_loss: 0.5023 - val_accuracy: 0.7724\n",
            "Epoch 359/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7637 - val_loss: 0.5018 - val_accuracy: 0.7724\n",
            "Epoch 360/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7699 - val_loss: 0.5011 - val_accuracy: 0.7642\n",
            "Epoch 361/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.7678 - val_loss: 0.5009 - val_accuracy: 0.7724\n",
            "Epoch 362/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.7678 - val_loss: 0.5000 - val_accuracy: 0.7642\n",
            "Epoch 363/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5025 - accuracy: 0.7617 - val_loss: 0.4990 - val_accuracy: 0.7724\n",
            "Epoch 364/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5019 - accuracy: 0.7637 - val_loss: 0.4988 - val_accuracy: 0.7642\n",
            "Epoch 365/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5013 - accuracy: 0.7678 - val_loss: 0.4978 - val_accuracy: 0.7724\n",
            "Epoch 366/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.7658 - val_loss: 0.4974 - val_accuracy: 0.7724\n",
            "Epoch 367/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.5003 - accuracy: 0.7719 - val_loss: 0.4973 - val_accuracy: 0.7642\n",
            "Epoch 368/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7658 - val_loss: 0.4968 - val_accuracy: 0.7642\n",
            "Epoch 369/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7699 - val_loss: 0.4963 - val_accuracy: 0.7642\n",
            "Epoch 370/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4990 - accuracy: 0.7699 - val_loss: 0.4958 - val_accuracy: 0.7724\n",
            "Epoch 371/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7678 - val_loss: 0.4944 - val_accuracy: 0.7724\n",
            "Epoch 372/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7699 - val_loss: 0.4942 - val_accuracy: 0.7724\n",
            "Epoch 373/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7719 - val_loss: 0.4937 - val_accuracy: 0.7724\n",
            "Epoch 374/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7658 - val_loss: 0.4930 - val_accuracy: 0.7724\n",
            "Epoch 375/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4969 - accuracy: 0.7699 - val_loss: 0.4928 - val_accuracy: 0.7724\n",
            "Epoch 376/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7699 - val_loss: 0.4930 - val_accuracy: 0.7724\n",
            "Epoch 377/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4957 - accuracy: 0.7780 - val_loss: 0.4933 - val_accuracy: 0.7642\n",
            "Epoch 378/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7699 - val_loss: 0.4924 - val_accuracy: 0.7724\n",
            "Epoch 379/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4951 - accuracy: 0.7719 - val_loss: 0.4921 - val_accuracy: 0.7724\n",
            "Epoch 380/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7699 - val_loss: 0.4906 - val_accuracy: 0.7724\n",
            "Epoch 381/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7719 - val_loss: 0.4897 - val_accuracy: 0.7805\n",
            "Epoch 382/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7739 - val_loss: 0.4896 - val_accuracy: 0.7724\n",
            "Epoch 383/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.7739 - val_loss: 0.4893 - val_accuracy: 0.7724\n",
            "Epoch 384/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.7719 - val_loss: 0.4889 - val_accuracy: 0.7724\n",
            "Epoch 385/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.7678 - val_loss: 0.4884 - val_accuracy: 0.7805\n",
            "Epoch 386/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4927 - accuracy: 0.7678 - val_loss: 0.4880 - val_accuracy: 0.7805\n",
            "Epoch 387/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7678 - val_loss: 0.4871 - val_accuracy: 0.7886\n",
            "Epoch 388/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7800 - val_loss: 0.4870 - val_accuracy: 0.7805\n",
            "Epoch 389/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4917 - accuracy: 0.7739 - val_loss: 0.4865 - val_accuracy: 0.7886\n",
            "Epoch 390/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4913 - accuracy: 0.7699 - val_loss: 0.4858 - val_accuracy: 0.7967\n",
            "Epoch 391/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7699 - val_loss: 0.4852 - val_accuracy: 0.8049\n",
            "Epoch 392/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7800 - val_loss: 0.4853 - val_accuracy: 0.7886\n",
            "Epoch 393/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.7780 - val_loss: 0.4851 - val_accuracy: 0.7886\n",
            "Epoch 394/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4902 - accuracy: 0.7739 - val_loss: 0.4848 - val_accuracy: 0.7886\n",
            "Epoch 395/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.7719 - val_loss: 0.4841 - val_accuracy: 0.7967\n",
            "Epoch 396/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.7780 - val_loss: 0.4841 - val_accuracy: 0.7967\n",
            "Epoch 397/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4892 - accuracy: 0.7739 - val_loss: 0.4835 - val_accuracy: 0.7967\n",
            "Epoch 398/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.7780 - val_loss: 0.4833 - val_accuracy: 0.7967\n",
            "Epoch 399/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4887 - accuracy: 0.7800 - val_loss: 0.4834 - val_accuracy: 0.7967\n",
            "Epoch 400/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7780 - val_loss: 0.4833 - val_accuracy: 0.7886\n",
            "Epoch 401/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4880 - accuracy: 0.7699 - val_loss: 0.4824 - val_accuracy: 0.7967\n",
            "Epoch 402/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7800 - val_loss: 0.4819 - val_accuracy: 0.8049\n",
            "Epoch 403/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.7821 - val_loss: 0.4821 - val_accuracy: 0.7967\n",
            "Epoch 404/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.7719 - val_loss: 0.4815 - val_accuracy: 0.7967\n",
            "Epoch 405/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.7719 - val_loss: 0.4807 - val_accuracy: 0.8049\n",
            "Epoch 406/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7862 - val_loss: 0.4805 - val_accuracy: 0.8049\n",
            "Epoch 407/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7821 - val_loss: 0.4809 - val_accuracy: 0.7967\n",
            "Epoch 408/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7760 - val_loss: 0.4798 - val_accuracy: 0.8049\n",
            "Epoch 409/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4860 - accuracy: 0.7862 - val_loss: 0.4801 - val_accuracy: 0.7967\n",
            "Epoch 410/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4858 - accuracy: 0.7800 - val_loss: 0.4798 - val_accuracy: 0.8049\n",
            "Epoch 411/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7780 - val_loss: 0.4797 - val_accuracy: 0.7967\n",
            "Epoch 412/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7821 - val_loss: 0.4794 - val_accuracy: 0.7967\n",
            "Epoch 413/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.7780 - val_loss: 0.4787 - val_accuracy: 0.8049\n",
            "Epoch 414/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4847 - accuracy: 0.7821 - val_loss: 0.4791 - val_accuracy: 0.7967\n",
            "Epoch 415/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4846 - accuracy: 0.7821 - val_loss: 0.4786 - val_accuracy: 0.8049\n",
            "Epoch 416/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7780 - val_loss: 0.4778 - val_accuracy: 0.8049\n",
            "Epoch 417/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.7821 - val_loss: 0.4775 - val_accuracy: 0.8049\n",
            "Epoch 418/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7780 - val_loss: 0.4771 - val_accuracy: 0.8049\n",
            "Epoch 419/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.7800 - val_loss: 0.4776 - val_accuracy: 0.8049\n",
            "Epoch 420/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.7841 - val_loss: 0.4768 - val_accuracy: 0.8049\n",
            "Epoch 421/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7821 - val_loss: 0.4763 - val_accuracy: 0.8049\n",
            "Epoch 422/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7841 - val_loss: 0.4765 - val_accuracy: 0.8049\n",
            "Epoch 423/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.7821 - val_loss: 0.4764 - val_accuracy: 0.8049\n",
            "Epoch 424/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7841 - val_loss: 0.4757 - val_accuracy: 0.8049\n",
            "Epoch 425/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.7841 - val_loss: 0.4753 - val_accuracy: 0.8049\n",
            "Epoch 426/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7882 - val_loss: 0.4753 - val_accuracy: 0.8049\n",
            "Epoch 427/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7760 - val_loss: 0.4747 - val_accuracy: 0.8049\n",
            "Epoch 428/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7841 - val_loss: 0.4744 - val_accuracy: 0.8049\n",
            "Epoch 429/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.7841 - val_loss: 0.4741 - val_accuracy: 0.8049\n",
            "Epoch 430/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.7800 - val_loss: 0.4742 - val_accuracy: 0.8049\n",
            "Epoch 431/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7841 - val_loss: 0.4738 - val_accuracy: 0.8049\n",
            "Epoch 432/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7841 - val_loss: 0.4736 - val_accuracy: 0.8049\n",
            "Epoch 433/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4814 - accuracy: 0.7821 - val_loss: 0.4733 - val_accuracy: 0.8049\n",
            "Epoch 434/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7882 - val_loss: 0.4732 - val_accuracy: 0.8049\n",
            "Epoch 435/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7862 - val_loss: 0.4732 - val_accuracy: 0.8049\n",
            "Epoch 436/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7841 - val_loss: 0.4727 - val_accuracy: 0.8049\n",
            "Epoch 437/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.7821 - val_loss: 0.4725 - val_accuracy: 0.8049\n",
            "Epoch 438/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.7821 - val_loss: 0.4722 - val_accuracy: 0.8049\n",
            "Epoch 439/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.7821 - val_loss: 0.4719 - val_accuracy: 0.8049\n",
            "Epoch 440/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.7800 - val_loss: 0.4720 - val_accuracy: 0.8049\n",
            "Epoch 441/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7882 - val_loss: 0.4717 - val_accuracy: 0.8049\n",
            "Epoch 442/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.7821 - val_loss: 0.4713 - val_accuracy: 0.8049\n",
            "Epoch 443/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.7841 - val_loss: 0.4711 - val_accuracy: 0.8049\n",
            "Epoch 444/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7882 - val_loss: 0.4709 - val_accuracy: 0.8049\n",
            "Epoch 445/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7821 - val_loss: 0.4708 - val_accuracy: 0.8049\n",
            "Epoch 446/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.7800 - val_loss: 0.4707 - val_accuracy: 0.8049\n",
            "Epoch 447/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7821 - val_loss: 0.4706 - val_accuracy: 0.8049\n",
            "Epoch 448/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.7821 - val_loss: 0.4705 - val_accuracy: 0.8049\n",
            "Epoch 449/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4787 - accuracy: 0.7841 - val_loss: 0.4700 - val_accuracy: 0.8049\n",
            "Epoch 450/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7862 - val_loss: 0.4699 - val_accuracy: 0.8049\n",
            "Epoch 451/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7862 - val_loss: 0.4696 - val_accuracy: 0.8049\n",
            "Epoch 452/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4782 - accuracy: 0.7862 - val_loss: 0.4695 - val_accuracy: 0.8049\n",
            "Epoch 453/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7800 - val_loss: 0.4697 - val_accuracy: 0.8049\n",
            "Epoch 454/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.7882 - val_loss: 0.4691 - val_accuracy: 0.8049\n",
            "Epoch 455/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7821 - val_loss: 0.4691 - val_accuracy: 0.8049\n",
            "Epoch 456/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.7841 - val_loss: 0.4688 - val_accuracy: 0.8049\n",
            "Epoch 457/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.7821 - val_loss: 0.4685 - val_accuracy: 0.8049\n",
            "Epoch 458/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4773 - accuracy: 0.7821 - val_loss: 0.4684 - val_accuracy: 0.8049\n",
            "Epoch 459/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.7862 - val_loss: 0.4683 - val_accuracy: 0.8049\n",
            "Epoch 460/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.7841 - val_loss: 0.4682 - val_accuracy: 0.8049\n",
            "Epoch 461/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7821 - val_loss: 0.4681 - val_accuracy: 0.8049\n",
            "Epoch 462/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7862 - val_loss: 0.4675 - val_accuracy: 0.8049\n",
            "Epoch 463/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.7821 - val_loss: 0.4672 - val_accuracy: 0.7967\n",
            "Epoch 464/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7800 - val_loss: 0.4670 - val_accuracy: 0.7886\n",
            "Epoch 465/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.7841 - val_loss: 0.4671 - val_accuracy: 0.8049\n",
            "Epoch 466/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7841 - val_loss: 0.4669 - val_accuracy: 0.8049\n",
            "Epoch 467/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.7862 - val_loss: 0.4670 - val_accuracy: 0.8049\n",
            "Epoch 468/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7862 - val_loss: 0.4664 - val_accuracy: 0.8049\n",
            "Epoch 469/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7780 - val_loss: 0.4665 - val_accuracy: 0.8049\n",
            "Epoch 470/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4759 - accuracy: 0.7821 - val_loss: 0.4661 - val_accuracy: 0.8049\n",
            "Epoch 471/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.7760 - val_loss: 0.4667 - val_accuracy: 0.8049\n",
            "Epoch 472/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7841 - val_loss: 0.4663 - val_accuracy: 0.8049\n",
            "Epoch 473/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7800 - val_loss: 0.4665 - val_accuracy: 0.8049\n",
            "Epoch 474/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4753 - accuracy: 0.7821 - val_loss: 0.4666 - val_accuracy: 0.8049\n",
            "Epoch 475/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4752 - accuracy: 0.7841 - val_loss: 0.4657 - val_accuracy: 0.8049\n",
            "Epoch 476/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.7841 - val_loss: 0.4655 - val_accuracy: 0.8049\n",
            "Epoch 477/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.7862 - val_loss: 0.4650 - val_accuracy: 0.8049\n",
            "Epoch 478/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7800 - val_loss: 0.4652 - val_accuracy: 0.8049\n",
            "Epoch 479/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.7821 - val_loss: 0.4658 - val_accuracy: 0.8049\n",
            "Epoch 480/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.7862 - val_loss: 0.4648 - val_accuracy: 0.8049\n",
            "Epoch 481/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7800 - val_loss: 0.4646 - val_accuracy: 0.8049\n",
            "Epoch 482/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4745 - accuracy: 0.7800 - val_loss: 0.4644 - val_accuracy: 0.8049\n",
            "Epoch 483/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.7821 - val_loss: 0.4640 - val_accuracy: 0.8049\n",
            "Epoch 484/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7739 - val_loss: 0.4644 - val_accuracy: 0.8049\n",
            "Epoch 485/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7841 - val_loss: 0.4641 - val_accuracy: 0.8049\n",
            "Epoch 486/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7800 - val_loss: 0.4645 - val_accuracy: 0.8049\n",
            "Epoch 487/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7800 - val_loss: 0.4642 - val_accuracy: 0.8049\n",
            "Epoch 488/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4739 - accuracy: 0.7800 - val_loss: 0.4637 - val_accuracy: 0.8049\n",
            "Epoch 489/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4735 - accuracy: 0.7800 - val_loss: 0.4641 - val_accuracy: 0.8049\n",
            "Epoch 490/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7841 - val_loss: 0.4632 - val_accuracy: 0.8049\n",
            "Epoch 491/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4733 - accuracy: 0.7800 - val_loss: 0.4640 - val_accuracy: 0.8049\n",
            "Epoch 492/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7882 - val_loss: 0.4628 - val_accuracy: 0.8049\n",
            "Epoch 493/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7760 - val_loss: 0.4633 - val_accuracy: 0.8049\n",
            "Epoch 494/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7821 - val_loss: 0.4630 - val_accuracy: 0.8049\n",
            "Epoch 495/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.7841 - val_loss: 0.4629 - val_accuracy: 0.8049\n",
            "Epoch 496/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7800 - val_loss: 0.4631 - val_accuracy: 0.8049\n",
            "Epoch 497/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.7841 - val_loss: 0.4620 - val_accuracy: 0.8130\n",
            "Epoch 498/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7800 - val_loss: 0.4621 - val_accuracy: 0.8049\n",
            "Epoch 499/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4621 - val_accuracy: 0.8049\n",
            "Epoch 500/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7800 - val_loss: 0.4621 - val_accuracy: 0.8049\n",
            "Epoch 501/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.7800 - val_loss: 0.4619 - val_accuracy: 0.8049\n",
            "Epoch 502/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.7821 - val_loss: 0.4621 - val_accuracy: 0.8049\n",
            "Epoch 503/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7800 - val_loss: 0.4617 - val_accuracy: 0.8049\n",
            "Epoch 504/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7780 - val_loss: 0.4614 - val_accuracy: 0.8049\n",
            "Epoch 505/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.7821 - val_loss: 0.4611 - val_accuracy: 0.8049\n",
            "Epoch 506/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.7780 - val_loss: 0.4610 - val_accuracy: 0.8049\n",
            "Epoch 507/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4720 - accuracy: 0.7821 - val_loss: 0.4610 - val_accuracy: 0.8049\n",
            "Epoch 508/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7800 - val_loss: 0.4612 - val_accuracy: 0.8049\n",
            "Epoch 509/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4717 - accuracy: 0.7780 - val_loss: 0.4612 - val_accuracy: 0.8049\n",
            "Epoch 510/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.7841 - val_loss: 0.4606 - val_accuracy: 0.8049\n",
            "Epoch 511/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7821 - val_loss: 0.4603 - val_accuracy: 0.8049\n",
            "Epoch 512/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7760 - val_loss: 0.4600 - val_accuracy: 0.8049\n",
            "Epoch 513/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7800 - val_loss: 0.4602 - val_accuracy: 0.8049\n",
            "Epoch 514/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7800 - val_loss: 0.4610 - val_accuracy: 0.8049\n",
            "Epoch 515/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4713 - accuracy: 0.7862 - val_loss: 0.4599 - val_accuracy: 0.8049\n",
            "Epoch 516/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7800 - val_loss: 0.4600 - val_accuracy: 0.8049\n",
            "Epoch 517/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.7800 - val_loss: 0.4600 - val_accuracy: 0.8049\n",
            "Epoch 518/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.7780 - val_loss: 0.4613 - val_accuracy: 0.8049\n",
            "Epoch 519/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.7821 - val_loss: 0.4598 - val_accuracy: 0.8049\n",
            "Epoch 520/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.7821 - val_loss: 0.4595 - val_accuracy: 0.8049\n",
            "Epoch 521/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4705 - accuracy: 0.7800 - val_loss: 0.4591 - val_accuracy: 0.8130\n",
            "Epoch 522/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.7780 - val_loss: 0.4591 - val_accuracy: 0.8049\n",
            "Epoch 523/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.7760 - val_loss: 0.4601 - val_accuracy: 0.8049\n",
            "Epoch 524/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7821 - val_loss: 0.4592 - val_accuracy: 0.8049\n",
            "Epoch 525/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7821 - val_loss: 0.4586 - val_accuracy: 0.8130\n",
            "Epoch 526/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7841 - val_loss: 0.4588 - val_accuracy: 0.8049\n",
            "Epoch 527/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.7780 - val_loss: 0.4585 - val_accuracy: 0.8130\n",
            "Epoch 528/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7780 - val_loss: 0.4584 - val_accuracy: 0.8130\n",
            "Epoch 529/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.7800 - val_loss: 0.4586 - val_accuracy: 0.8049\n",
            "Epoch 530/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7800 - val_loss: 0.4586 - val_accuracy: 0.8049\n",
            "Epoch 531/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4698 - accuracy: 0.7780 - val_loss: 0.4581 - val_accuracy: 0.8130\n",
            "Epoch 532/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.7780 - val_loss: 0.4584 - val_accuracy: 0.8049\n",
            "Epoch 533/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7821 - val_loss: 0.4580 - val_accuracy: 0.8049\n",
            "Epoch 534/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.7841 - val_loss: 0.4581 - val_accuracy: 0.8049\n",
            "Epoch 535/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4696 - accuracy: 0.7760 - val_loss: 0.4578 - val_accuracy: 0.8049\n",
            "Epoch 536/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.7862 - val_loss: 0.4578 - val_accuracy: 0.8049\n",
            "Epoch 537/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7800 - val_loss: 0.4589 - val_accuracy: 0.8049\n",
            "Epoch 538/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7800 - val_loss: 0.4574 - val_accuracy: 0.8130\n",
            "Epoch 539/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.7841 - val_loss: 0.4583 - val_accuracy: 0.8049\n",
            "Epoch 540/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7780 - val_loss: 0.4575 - val_accuracy: 0.8049\n",
            "Epoch 541/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7841 - val_loss: 0.4575 - val_accuracy: 0.8049\n",
            "Epoch 542/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7841 - val_loss: 0.4576 - val_accuracy: 0.8049\n",
            "Epoch 543/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4688 - accuracy: 0.7780 - val_loss: 0.4576 - val_accuracy: 0.8049\n",
            "Epoch 544/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.7821 - val_loss: 0.4569 - val_accuracy: 0.8049\n",
            "Epoch 545/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7739 - val_loss: 0.4575 - val_accuracy: 0.8049\n",
            "Epoch 546/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.7780 - val_loss: 0.4569 - val_accuracy: 0.8049\n",
            "Epoch 547/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.7780 - val_loss: 0.4566 - val_accuracy: 0.8049\n",
            "Epoch 548/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7739 - val_loss: 0.4574 - val_accuracy: 0.8049\n",
            "Epoch 549/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7821 - val_loss: 0.4568 - val_accuracy: 0.8049\n",
            "Epoch 550/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7800 - val_loss: 0.4562 - val_accuracy: 0.8130\n",
            "Epoch 551/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4685 - accuracy: 0.7821 - val_loss: 0.4561 - val_accuracy: 0.8049\n",
            "Epoch 552/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7841 - val_loss: 0.4559 - val_accuracy: 0.8130\n",
            "Epoch 553/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7800 - val_loss: 0.4557 - val_accuracy: 0.8130\n",
            "Epoch 554/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4681 - accuracy: 0.7841 - val_loss: 0.4554 - val_accuracy: 0.8130\n",
            "Epoch 555/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7739 - val_loss: 0.4562 - val_accuracy: 0.8049\n",
            "Epoch 556/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7800 - val_loss: 0.4559 - val_accuracy: 0.8049\n",
            "Epoch 557/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.7841 - val_loss: 0.4556 - val_accuracy: 0.8049\n",
            "Epoch 558/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7780 - val_loss: 0.4555 - val_accuracy: 0.8049\n",
            "Epoch 559/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7800 - val_loss: 0.4549 - val_accuracy: 0.8130\n",
            "Epoch 560/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7760 - val_loss: 0.4551 - val_accuracy: 0.8049\n",
            "Epoch 561/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.7821 - val_loss: 0.4549 - val_accuracy: 0.8130\n",
            "Epoch 562/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7780 - val_loss: 0.4558 - val_accuracy: 0.8049\n",
            "Epoch 563/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4677 - accuracy: 0.7841 - val_loss: 0.4553 - val_accuracy: 0.8049\n",
            "Epoch 564/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.7821 - val_loss: 0.4547 - val_accuracy: 0.8049\n",
            "Epoch 565/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7821 - val_loss: 0.4550 - val_accuracy: 0.8049\n",
            "Epoch 566/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7760 - val_loss: 0.4548 - val_accuracy: 0.8049\n",
            "Epoch 567/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7760 - val_loss: 0.4549 - val_accuracy: 0.8049\n",
            "Epoch 568/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.7841 - val_loss: 0.4551 - val_accuracy: 0.8049\n",
            "Epoch 569/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.7821 - val_loss: 0.4541 - val_accuracy: 0.8130\n",
            "Epoch 570/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7800 - val_loss: 0.4540 - val_accuracy: 0.8130\n",
            "Epoch 571/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.7800 - val_loss: 0.4539 - val_accuracy: 0.8130\n",
            "Epoch 572/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7800 - val_loss: 0.4537 - val_accuracy: 0.8130\n",
            "Epoch 573/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7780 - val_loss: 0.4539 - val_accuracy: 0.8049\n",
            "Epoch 574/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7800 - val_loss: 0.4540 - val_accuracy: 0.8049\n",
            "Epoch 575/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4667 - accuracy: 0.7800 - val_loss: 0.4543 - val_accuracy: 0.8049\n",
            "Epoch 576/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7821 - val_loss: 0.4535 - val_accuracy: 0.8130\n",
            "Epoch 577/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7760 - val_loss: 0.4542 - val_accuracy: 0.8049\n",
            "Epoch 578/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.7862 - val_loss: 0.4537 - val_accuracy: 0.8049\n",
            "Epoch 579/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4666 - accuracy: 0.7841 - val_loss: 0.4530 - val_accuracy: 0.8130\n",
            "Epoch 580/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.7699 - val_loss: 0.4536 - val_accuracy: 0.8049\n",
            "Epoch 581/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7760 - val_loss: 0.4543 - val_accuracy: 0.8049\n",
            "Epoch 582/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7780 - val_loss: 0.4528 - val_accuracy: 0.8130\n",
            "Epoch 583/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4656 - accuracy: 0.7780 - val_loss: 0.4537 - val_accuracy: 0.8049\n",
            "Epoch 584/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7760 - val_loss: 0.4550 - val_accuracy: 0.8049\n",
            "Epoch 585/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7760 - val_loss: 0.4537 - val_accuracy: 0.8049\n",
            "Epoch 586/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7739 - val_loss: 0.4531 - val_accuracy: 0.8049\n",
            "Epoch 587/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7760 - val_loss: 0.4531 - val_accuracy: 0.8049\n",
            "Epoch 588/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7739 - val_loss: 0.4527 - val_accuracy: 0.8049\n",
            "Epoch 589/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7780 - val_loss: 0.4524 - val_accuracy: 0.8130\n",
            "Epoch 590/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.7821 - val_loss: 0.4534 - val_accuracy: 0.8049\n",
            "Epoch 591/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.7760 - val_loss: 0.4524 - val_accuracy: 0.8130\n",
            "Epoch 592/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4649 - accuracy: 0.7780 - val_loss: 0.4533 - val_accuracy: 0.8049\n",
            "Epoch 593/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4657 - accuracy: 0.7800 - val_loss: 0.4521 - val_accuracy: 0.8130\n",
            "Epoch 594/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.7719 - val_loss: 0.4520 - val_accuracy: 0.8130\n",
            "Epoch 595/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4653 - accuracy: 0.7699 - val_loss: 0.4522 - val_accuracy: 0.8049\n",
            "Epoch 596/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7800 - val_loss: 0.4523 - val_accuracy: 0.8049\n",
            "Epoch 597/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7780 - val_loss: 0.4529 - val_accuracy: 0.8049\n",
            "Epoch 598/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7800 - val_loss: 0.4518 - val_accuracy: 0.8130\n",
            "Epoch 599/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7780 - val_loss: 0.4513 - val_accuracy: 0.8130\n",
            "Epoch 600/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4652 - accuracy: 0.7719 - val_loss: 0.4514 - val_accuracy: 0.8130\n",
            "Epoch 601/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7739 - val_loss: 0.4512 - val_accuracy: 0.8130\n",
            "Epoch 602/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4650 - accuracy: 0.7719 - val_loss: 0.4512 - val_accuracy: 0.8130\n",
            "Epoch 603/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7699 - val_loss: 0.4520 - val_accuracy: 0.8049\n",
            "Epoch 604/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7739 - val_loss: 0.4518 - val_accuracy: 0.8049\n",
            "Epoch 605/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.7760 - val_loss: 0.4511 - val_accuracy: 0.8130\n",
            "Epoch 606/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7739 - val_loss: 0.4520 - val_accuracy: 0.8049\n",
            "Epoch 607/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.7739 - val_loss: 0.4512 - val_accuracy: 0.8049\n",
            "Epoch 608/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7699 - val_loss: 0.4517 - val_accuracy: 0.8049\n",
            "Epoch 609/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7862 - val_loss: 0.4504 - val_accuracy: 0.8049\n",
            "Epoch 610/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7678 - val_loss: 0.4504 - val_accuracy: 0.8130\n",
            "Epoch 611/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.7719 - val_loss: 0.4503 - val_accuracy: 0.8049\n",
            "Epoch 612/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7699 - val_loss: 0.4505 - val_accuracy: 0.8130\n",
            "Epoch 613/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.7739 - val_loss: 0.4506 - val_accuracy: 0.8130\n",
            "Epoch 614/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4642 - accuracy: 0.7760 - val_loss: 0.4505 - val_accuracy: 0.8130\n",
            "Epoch 615/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7719 - val_loss: 0.4506 - val_accuracy: 0.8130\n",
            "Epoch 616/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.7719 - val_loss: 0.4501 - val_accuracy: 0.8130\n",
            "Epoch 617/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7780 - val_loss: 0.4497 - val_accuracy: 0.7967\n",
            "Epoch 618/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7678 - val_loss: 0.4500 - val_accuracy: 0.8130\n",
            "Epoch 619/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.7719 - val_loss: 0.4502 - val_accuracy: 0.8130\n",
            "Epoch 620/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.7678 - val_loss: 0.4499 - val_accuracy: 0.8130\n",
            "Epoch 621/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7719 - val_loss: 0.4502 - val_accuracy: 0.8130\n",
            "Epoch 622/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7739 - val_loss: 0.4496 - val_accuracy: 0.8130\n",
            "Epoch 623/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4638 - accuracy: 0.7719 - val_loss: 0.4502 - val_accuracy: 0.8049\n",
            "Epoch 624/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7699 - val_loss: 0.4496 - val_accuracy: 0.8130\n",
            "Epoch 625/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7739 - val_loss: 0.4493 - val_accuracy: 0.8049\n",
            "Epoch 626/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.7678 - val_loss: 0.4492 - val_accuracy: 0.7967\n",
            "Epoch 627/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7719 - val_loss: 0.4491 - val_accuracy: 0.7967\n",
            "Epoch 628/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4636 - accuracy: 0.7637 - val_loss: 0.4497 - val_accuracy: 0.8130\n",
            "Epoch 629/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.7719 - val_loss: 0.4496 - val_accuracy: 0.8130\n",
            "Epoch 630/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7719 - val_loss: 0.4495 - val_accuracy: 0.8130\n",
            "Epoch 631/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4631 - accuracy: 0.7719 - val_loss: 0.4506 - val_accuracy: 0.8049\n",
            "Epoch 632/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.7780 - val_loss: 0.4489 - val_accuracy: 0.8049\n",
            "Epoch 633/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7719 - val_loss: 0.4487 - val_accuracy: 0.7967\n",
            "Epoch 634/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.7719 - val_loss: 0.4495 - val_accuracy: 0.8049\n",
            "Epoch 635/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7760 - val_loss: 0.4486 - val_accuracy: 0.8049\n",
            "Epoch 636/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7719 - val_loss: 0.4498 - val_accuracy: 0.8049\n",
            "Epoch 637/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.7739 - val_loss: 0.4491 - val_accuracy: 0.8130\n",
            "Epoch 638/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7780 - val_loss: 0.4486 - val_accuracy: 0.8049\n",
            "Epoch 639/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4629 - accuracy: 0.7699 - val_loss: 0.4491 - val_accuracy: 0.8130\n",
            "Epoch 640/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7719 - val_loss: 0.4484 - val_accuracy: 0.7967\n",
            "Epoch 641/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7699 - val_loss: 0.4486 - val_accuracy: 0.8049\n",
            "Epoch 642/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.7719 - val_loss: 0.4484 - val_accuracy: 0.8049\n",
            "Epoch 643/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7719 - val_loss: 0.4481 - val_accuracy: 0.7967\n",
            "Epoch 644/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4627 - accuracy: 0.7739 - val_loss: 0.4486 - val_accuracy: 0.8130\n",
            "Epoch 645/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7678 - val_loss: 0.4484 - val_accuracy: 0.8049\n",
            "Epoch 646/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.7719 - val_loss: 0.4483 - val_accuracy: 0.8049\n",
            "Epoch 647/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7699 - val_loss: 0.4482 - val_accuracy: 0.8049\n",
            "Epoch 648/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7699 - val_loss: 0.4481 - val_accuracy: 0.8049\n",
            "Epoch 649/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7699 - val_loss: 0.4486 - val_accuracy: 0.8130\n",
            "Epoch 650/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7699 - val_loss: 0.4489 - val_accuracy: 0.8049\n",
            "Epoch 651/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.7699 - val_loss: 0.4480 - val_accuracy: 0.8049\n",
            "Epoch 652/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7719 - val_loss: 0.4485 - val_accuracy: 0.8130\n",
            "Epoch 653/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.7780 - val_loss: 0.4476 - val_accuracy: 0.7967\n",
            "Epoch 654/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7719 - val_loss: 0.4478 - val_accuracy: 0.8049\n",
            "Epoch 655/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7637 - val_loss: 0.4492 - val_accuracy: 0.8049\n",
            "Epoch 656/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7699 - val_loss: 0.4491 - val_accuracy: 0.8049\n",
            "Epoch 657/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7637 - val_loss: 0.4500 - val_accuracy: 0.8049\n",
            "Epoch 658/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.7719 - val_loss: 0.4479 - val_accuracy: 0.8049\n",
            "Epoch 659/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7699 - val_loss: 0.4474 - val_accuracy: 0.8049\n",
            "Epoch 660/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7739 - val_loss: 0.4474 - val_accuracy: 0.8049\n",
            "Epoch 661/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.7719 - val_loss: 0.4473 - val_accuracy: 0.8049\n",
            "Epoch 662/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7678 - val_loss: 0.4478 - val_accuracy: 0.8049\n",
            "Epoch 663/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4621 - accuracy: 0.7719 - val_loss: 0.4473 - val_accuracy: 0.8049\n",
            "Epoch 664/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7699 - val_loss: 0.4470 - val_accuracy: 0.8049\n",
            "Epoch 665/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.7719 - val_loss: 0.4479 - val_accuracy: 0.8130\n",
            "Epoch 666/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7699 - val_loss: 0.4471 - val_accuracy: 0.8049\n",
            "Epoch 667/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4622 - accuracy: 0.7699 - val_loss: 0.4469 - val_accuracy: 0.7967\n",
            "Epoch 668/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7699 - val_loss: 0.4472 - val_accuracy: 0.8049\n",
            "Epoch 669/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7739 - val_loss: 0.4468 - val_accuracy: 0.7967\n",
            "Epoch 670/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7658 - val_loss: 0.4476 - val_accuracy: 0.8049\n",
            "Epoch 671/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.7739 - val_loss: 0.4468 - val_accuracy: 0.8049\n",
            "Epoch 672/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.7719 - val_loss: 0.4473 - val_accuracy: 0.8049\n",
            "Epoch 673/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7699 - val_loss: 0.4469 - val_accuracy: 0.8049\n",
            "Epoch 674/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7780 - val_loss: 0.4466 - val_accuracy: 0.8049\n",
            "Epoch 675/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7699 - val_loss: 0.4472 - val_accuracy: 0.8049\n",
            "Epoch 676/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7678 - val_loss: 0.4481 - val_accuracy: 0.8049\n",
            "Epoch 677/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7739 - val_loss: 0.4466 - val_accuracy: 0.8049\n",
            "Epoch 678/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.7658 - val_loss: 0.4465 - val_accuracy: 0.7967\n",
            "Epoch 679/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.7699 - val_loss: 0.4470 - val_accuracy: 0.8049\n",
            "Epoch 680/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7699 - val_loss: 0.4472 - val_accuracy: 0.8049\n",
            "Epoch 681/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7719 - val_loss: 0.4462 - val_accuracy: 0.7967\n",
            "Epoch 682/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7678 - val_loss: 0.4478 - val_accuracy: 0.8049\n",
            "Epoch 683/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.7699 - val_loss: 0.4478 - val_accuracy: 0.8049\n",
            "Epoch 684/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7719 - val_loss: 0.4470 - val_accuracy: 0.8049\n",
            "Epoch 685/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.7719 - val_loss: 0.4464 - val_accuracy: 0.8049\n",
            "Epoch 686/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7699 - val_loss: 0.4460 - val_accuracy: 0.7967\n",
            "Epoch 687/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4613 - accuracy: 0.7658 - val_loss: 0.4464 - val_accuracy: 0.8049\n",
            "Epoch 688/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7678 - val_loss: 0.4469 - val_accuracy: 0.8049\n",
            "Epoch 689/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7719 - val_loss: 0.4461 - val_accuracy: 0.8049\n",
            "Epoch 690/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4610 - accuracy: 0.7678 - val_loss: 0.4459 - val_accuracy: 0.7967\n",
            "Epoch 691/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7739 - val_loss: 0.4458 - val_accuracy: 0.8049\n",
            "Epoch 692/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7699 - val_loss: 0.4458 - val_accuracy: 0.7967\n",
            "Epoch 693/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4609 - accuracy: 0.7699 - val_loss: 0.4459 - val_accuracy: 0.8049\n",
            "Epoch 694/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7719 - val_loss: 0.4457 - val_accuracy: 0.7967\n",
            "Epoch 695/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4611 - accuracy: 0.7739 - val_loss: 0.4462 - val_accuracy: 0.8049\n",
            "Epoch 696/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7699 - val_loss: 0.4460 - val_accuracy: 0.8049\n",
            "Epoch 697/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7719 - val_loss: 0.4458 - val_accuracy: 0.8049\n",
            "Epoch 698/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4608 - accuracy: 0.7678 - val_loss: 0.4459 - val_accuracy: 0.8049\n",
            "Epoch 699/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7719 - val_loss: 0.4455 - val_accuracy: 0.8049\n",
            "Epoch 700/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7678 - val_loss: 0.4455 - val_accuracy: 0.8049\n",
            "Epoch 701/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7699 - val_loss: 0.4464 - val_accuracy: 0.8049\n",
            "Epoch 702/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7739 - val_loss: 0.4457 - val_accuracy: 0.8049\n",
            "Epoch 703/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7719 - val_loss: 0.4455 - val_accuracy: 0.7967\n",
            "Epoch 704/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7699 - val_loss: 0.4455 - val_accuracy: 0.7967\n",
            "Epoch 705/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7678 - val_loss: 0.4461 - val_accuracy: 0.8049\n",
            "Epoch 706/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7719 - val_loss: 0.4462 - val_accuracy: 0.8049\n",
            "Epoch 707/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7699 - val_loss: 0.4465 - val_accuracy: 0.7967\n",
            "Epoch 708/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4607 - accuracy: 0.7699 - val_loss: 0.4463 - val_accuracy: 0.8049\n",
            "Epoch 709/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7678 - val_loss: 0.4453 - val_accuracy: 0.8049\n",
            "Epoch 710/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7719 - val_loss: 0.4453 - val_accuracy: 0.8049\n",
            "Epoch 711/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7678 - val_loss: 0.4453 - val_accuracy: 0.8049\n",
            "Epoch 712/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4604 - accuracy: 0.7699 - val_loss: 0.4454 - val_accuracy: 0.8049\n",
            "Epoch 713/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7719 - val_loss: 0.4450 - val_accuracy: 0.7967\n",
            "Epoch 714/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7658 - val_loss: 0.4461 - val_accuracy: 0.7967\n",
            "Epoch 715/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7719 - val_loss: 0.4449 - val_accuracy: 0.7967\n",
            "Epoch 716/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7678 - val_loss: 0.4450 - val_accuracy: 0.7967\n",
            "Epoch 717/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7678 - val_loss: 0.4449 - val_accuracy: 0.8049\n",
            "Epoch 718/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7739 - val_loss: 0.4448 - val_accuracy: 0.8049\n",
            "Epoch 719/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4603 - accuracy: 0.7739 - val_loss: 0.4448 - val_accuracy: 0.7967\n",
            "Epoch 720/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7719 - val_loss: 0.4449 - val_accuracy: 0.8049\n",
            "Epoch 721/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7699 - val_loss: 0.4447 - val_accuracy: 0.8049\n",
            "Epoch 722/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4601 - accuracy: 0.7699 - val_loss: 0.4450 - val_accuracy: 0.8049\n",
            "Epoch 723/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7719 - val_loss: 0.4450 - val_accuracy: 0.8049\n",
            "Epoch 724/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7678 - val_loss: 0.4448 - val_accuracy: 0.8049\n",
            "Epoch 725/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7719 - val_loss: 0.4449 - val_accuracy: 0.8049\n",
            "Epoch 726/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4598 - accuracy: 0.7699 - val_loss: 0.4449 - val_accuracy: 0.8049\n",
            "Epoch 727/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7678 - val_loss: 0.4448 - val_accuracy: 0.8049\n",
            "Epoch 728/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7658 - val_loss: 0.4445 - val_accuracy: 0.8049\n",
            "Epoch 729/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4599 - accuracy: 0.7678 - val_loss: 0.4447 - val_accuracy: 0.8049\n",
            "Epoch 730/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4593 - accuracy: 0.7739 - val_loss: 0.4444 - val_accuracy: 0.8049\n",
            "Epoch 731/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7678 - val_loss: 0.4452 - val_accuracy: 0.8049\n",
            "Epoch 732/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7719 - val_loss: 0.4448 - val_accuracy: 0.8049\n",
            "Epoch 733/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4597 - accuracy: 0.7658 - val_loss: 0.4448 - val_accuracy: 0.8049\n",
            "Epoch 734/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7739 - val_loss: 0.4444 - val_accuracy: 0.7967\n",
            "Epoch 735/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7658 - val_loss: 0.4446 - val_accuracy: 0.8049\n",
            "Epoch 736/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7699 - val_loss: 0.4449 - val_accuracy: 0.8049\n",
            "Epoch 737/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7678 - val_loss: 0.4453 - val_accuracy: 0.8049\n",
            "Epoch 738/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4596 - accuracy: 0.7719 - val_loss: 0.4450 - val_accuracy: 0.8049\n",
            "Epoch 739/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7699 - val_loss: 0.4452 - val_accuracy: 0.8049\n",
            "Epoch 740/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 0.7719 - val_loss: 0.4444 - val_accuracy: 0.8049\n",
            "Epoch 741/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7760 - val_loss: 0.4440 - val_accuracy: 0.8049\n",
            "Epoch 742/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7678 - val_loss: 0.4440 - val_accuracy: 0.8049\n",
            "Epoch 743/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4590 - accuracy: 0.7719 - val_loss: 0.4441 - val_accuracy: 0.7967\n",
            "Epoch 744/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7678 - val_loss: 0.4440 - val_accuracy: 0.7967\n",
            "Epoch 745/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7658 - val_loss: 0.4444 - val_accuracy: 0.8049\n",
            "Epoch 746/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7739 - val_loss: 0.4442 - val_accuracy: 0.8049\n",
            "Epoch 747/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7699 - val_loss: 0.4440 - val_accuracy: 0.8049\n",
            "Epoch 748/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4592 - accuracy: 0.7658 - val_loss: 0.4443 - val_accuracy: 0.8049\n",
            "Epoch 749/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7678 - val_loss: 0.4450 - val_accuracy: 0.8049\n",
            "Epoch 750/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7699 - val_loss: 0.4439 - val_accuracy: 0.7967\n",
            "Epoch 751/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4588 - accuracy: 0.7699 - val_loss: 0.4441 - val_accuracy: 0.8049\n",
            "Epoch 752/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7739 - val_loss: 0.4443 - val_accuracy: 0.8049\n",
            "Epoch 753/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7699 - val_loss: 0.4438 - val_accuracy: 0.7967\n",
            "Epoch 754/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7739 - val_loss: 0.4453 - val_accuracy: 0.7967\n",
            "Epoch 755/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4591 - accuracy: 0.7719 - val_loss: 0.4443 - val_accuracy: 0.8049\n",
            "Epoch 756/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7699 - val_loss: 0.4436 - val_accuracy: 0.7967\n",
            "Epoch 757/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7678 - val_loss: 0.4438 - val_accuracy: 0.8049\n",
            "Epoch 758/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4589 - accuracy: 0.7699 - val_loss: 0.4438 - val_accuracy: 0.8049\n",
            "Epoch 759/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7637 - val_loss: 0.4449 - val_accuracy: 0.7967\n",
            "Epoch 760/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7739 - val_loss: 0.4436 - val_accuracy: 0.7967\n",
            "Epoch 761/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7658 - val_loss: 0.4440 - val_accuracy: 0.8049\n",
            "Epoch 762/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7699 - val_loss: 0.4437 - val_accuracy: 0.8049\n",
            "Epoch 763/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7739 - val_loss: 0.4446 - val_accuracy: 0.8049\n",
            "Epoch 764/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7699 - val_loss: 0.4436 - val_accuracy: 0.8049\n",
            "Epoch 765/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7699 - val_loss: 0.4434 - val_accuracy: 0.8049\n",
            "Epoch 766/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7719 - val_loss: 0.4443 - val_accuracy: 0.8049\n",
            "Epoch 767/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7678 - val_loss: 0.4442 - val_accuracy: 0.8049\n",
            "Epoch 768/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7739 - val_loss: 0.4438 - val_accuracy: 0.8049\n",
            "Epoch 769/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7719 - val_loss: 0.4439 - val_accuracy: 0.8049\n",
            "Epoch 770/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7658 - val_loss: 0.4434 - val_accuracy: 0.7967\n",
            "Epoch 771/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7658 - val_loss: 0.4439 - val_accuracy: 0.8049\n",
            "Epoch 772/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7658 - val_loss: 0.4440 - val_accuracy: 0.8049\n",
            "Epoch 773/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7739 - val_loss: 0.4444 - val_accuracy: 0.8049\n",
            "Epoch 774/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7739 - val_loss: 0.4443 - val_accuracy: 0.8049\n",
            "Epoch 775/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7739 - val_loss: 0.4437 - val_accuracy: 0.8049\n",
            "Epoch 776/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4586 - accuracy: 0.7699 - val_loss: 0.4437 - val_accuracy: 0.8049\n",
            "Epoch 777/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4582 - accuracy: 0.7678 - val_loss: 0.4441 - val_accuracy: 0.8049\n",
            "Epoch 778/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4585 - accuracy: 0.7658 - val_loss: 0.4440 - val_accuracy: 0.8049\n",
            "Epoch 779/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7719 - val_loss: 0.4438 - val_accuracy: 0.8049\n",
            "Epoch 780/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7699 - val_loss: 0.4443 - val_accuracy: 0.8049\n",
            "Epoch 781/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4583 - accuracy: 0.7699 - val_loss: 0.4441 - val_accuracy: 0.8049\n",
            "Epoch 782/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.7739 - val_loss: 0.4436 - val_accuracy: 0.8049\n",
            "Epoch 783/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7719 - val_loss: 0.4437 - val_accuracy: 0.8049\n",
            "Epoch 784/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4582 - accuracy: 0.7760 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 785/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7719 - val_loss: 0.4431 - val_accuracy: 0.7967\n",
            "Epoch 786/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7658 - val_loss: 0.4448 - val_accuracy: 0.7967\n",
            "Epoch 787/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7739 - val_loss: 0.4446 - val_accuracy: 0.7967\n",
            "Epoch 788/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7760 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 789/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4581 - accuracy: 0.7760 - val_loss: 0.4431 - val_accuracy: 0.7967\n",
            "Epoch 790/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7678 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 791/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7719 - val_loss: 0.4435 - val_accuracy: 0.8049\n",
            "Epoch 792/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7699 - val_loss: 0.4436 - val_accuracy: 0.8049\n",
            "Epoch 793/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.7760 - val_loss: 0.4437 - val_accuracy: 0.8049\n",
            "Epoch 794/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7760 - val_loss: 0.4431 - val_accuracy: 0.7967\n",
            "Epoch 795/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7719 - val_loss: 0.4435 - val_accuracy: 0.8049\n",
            "Epoch 796/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7739 - val_loss: 0.4432 - val_accuracy: 0.8049\n",
            "Epoch 797/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7678 - val_loss: 0.4434 - val_accuracy: 0.8049\n",
            "Epoch 798/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7699 - val_loss: 0.4430 - val_accuracy: 0.7967\n",
            "Epoch 799/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7678 - val_loss: 0.4447 - val_accuracy: 0.7967\n",
            "Epoch 800/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4578 - accuracy: 0.7719 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 801/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7678 - val_loss: 0.4438 - val_accuracy: 0.8049\n",
            "Epoch 802/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7719 - val_loss: 0.4435 - val_accuracy: 0.8049\n",
            "Epoch 803/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7658 - val_loss: 0.4438 - val_accuracy: 0.8049\n",
            "Epoch 804/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4577 - accuracy: 0.7760 - val_loss: 0.4434 - val_accuracy: 0.8049\n",
            "Epoch 805/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7719 - val_loss: 0.4435 - val_accuracy: 0.8049\n",
            "Epoch 806/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7658 - val_loss: 0.4432 - val_accuracy: 0.8049\n",
            "Epoch 807/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7780 - val_loss: 0.4436 - val_accuracy: 0.8049\n",
            "Epoch 808/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4573 - accuracy: 0.7739 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 809/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7739 - val_loss: 0.4438 - val_accuracy: 0.8049\n",
            "Epoch 810/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7719 - val_loss: 0.4434 - val_accuracy: 0.8049\n",
            "Epoch 811/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4576 - accuracy: 0.7719 - val_loss: 0.4432 - val_accuracy: 0.8049\n",
            "Epoch 812/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7719 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 813/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4446 - val_accuracy: 0.7967\n",
            "Epoch 814/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4574 - accuracy: 0.7719 - val_loss: 0.4438 - val_accuracy: 0.8049\n",
            "Epoch 815/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.7699 - val_loss: 0.4435 - val_accuracy: 0.8049\n",
            "Epoch 816/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.7739 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 817/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7699 - val_loss: 0.4439 - val_accuracy: 0.7967\n",
            "Epoch 818/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7699 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 819/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7719 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 820/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7719 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 821/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7719 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 822/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 823/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7719 - val_loss: 0.4435 - val_accuracy: 0.8049\n",
            "Epoch 824/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7678 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 825/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7699 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 826/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4556 - accuracy: 0.7719 - val_loss: 0.4428 - val_accuracy: 0.8049\n",
            "Epoch 827/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.7739 - val_loss: 0.4434 - val_accuracy: 0.8049\n",
            "Epoch 828/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7719 - val_loss: 0.4434 - val_accuracy: 0.8049\n",
            "Epoch 829/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7699 - val_loss: 0.4435 - val_accuracy: 0.8049\n",
            "Epoch 830/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4572 - accuracy: 0.7699 - val_loss: 0.4435 - val_accuracy: 0.8049\n",
            "Epoch 831/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7739 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 832/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7760 - val_loss: 0.4432 - val_accuracy: 0.8049\n",
            "Epoch 833/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7739 - val_loss: 0.4432 - val_accuracy: 0.8049\n",
            "Epoch 834/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4560 - accuracy: 0.7739 - val_loss: 0.4428 - val_accuracy: 0.8049\n",
            "Epoch 835/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7699 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 836/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7699 - val_loss: 0.4429 - val_accuracy: 0.8049\n",
            "Epoch 837/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7739 - val_loss: 0.4434 - val_accuracy: 0.8049\n",
            "Epoch 838/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4561 - accuracy: 0.7739 - val_loss: 0.4446 - val_accuracy: 0.7967\n",
            "Epoch 839/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7739 - val_loss: 0.4437 - val_accuracy: 0.8049\n",
            "Epoch 840/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7739 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 841/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7678 - val_loss: 0.4434 - val_accuracy: 0.8049\n",
            "Epoch 842/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7699 - val_loss: 0.4434 - val_accuracy: 0.8049\n",
            "Epoch 843/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.7699 - val_loss: 0.4444 - val_accuracy: 0.7967\n",
            "Epoch 844/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7739 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 845/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4567 - accuracy: 0.7739 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 846/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7678 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 847/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 0.7699 - val_loss: 0.4439 - val_accuracy: 0.7967\n",
            "Epoch 848/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7699 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 849/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7699 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 850/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4566 - accuracy: 0.7719 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 851/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4564 - accuracy: 0.7719 - val_loss: 0.4434 - val_accuracy: 0.8049\n",
            "Epoch 852/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7699 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 853/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7699 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 854/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7699 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 855/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4561 - accuracy: 0.7699 - val_loss: 0.4434 - val_accuracy: 0.8049\n",
            "Epoch 856/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7699 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 857/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4559 - accuracy: 0.7719 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 858/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7760 - val_loss: 0.4436 - val_accuracy: 0.7967\n",
            "Epoch 859/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7780 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 860/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7862 - val_loss: 0.4428 - val_accuracy: 0.8049\n",
            "Epoch 861/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7780 - val_loss: 0.4436 - val_accuracy: 0.8049\n",
            "Epoch 862/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4558 - accuracy: 0.7699 - val_loss: 0.4437 - val_accuracy: 0.7967\n",
            "Epoch 863/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7719 - val_loss: 0.4439 - val_accuracy: 0.7967\n",
            "Epoch 864/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7719 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 865/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4559 - accuracy: 0.7739 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 866/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7719 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 867/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7719 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 868/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7719 - val_loss: 0.4440 - val_accuracy: 0.7967\n",
            "Epoch 869/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7699 - val_loss: 0.4445 - val_accuracy: 0.7967\n",
            "Epoch 870/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7678 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 871/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7739 - val_loss: 0.4446 - val_accuracy: 0.7967\n",
            "Epoch 872/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4557 - accuracy: 0.7699 - val_loss: 0.4445 - val_accuracy: 0.7967\n",
            "Epoch 873/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7780 - val_loss: 0.4435 - val_accuracy: 0.8049\n",
            "Epoch 874/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7760 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 875/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7760 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 876/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7739 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 877/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4555 - accuracy: 0.7739 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 878/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7739 - val_loss: 0.4434 - val_accuracy: 0.7967\n",
            "Epoch 879/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7760 - val_loss: 0.4427 - val_accuracy: 0.7967\n",
            "Epoch 880/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7739 - val_loss: 0.4435 - val_accuracy: 0.7967\n",
            "Epoch 881/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.7699 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 882/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7719 - val_loss: 0.4434 - val_accuracy: 0.7967\n",
            "Epoch 883/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.7719 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 884/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4553 - accuracy: 0.7739 - val_loss: 0.4434 - val_accuracy: 0.8049\n",
            "Epoch 885/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4552 - accuracy: 0.7760 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 886/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7699 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 887/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7821 - val_loss: 0.4457 - val_accuracy: 0.7967\n",
            "Epoch 888/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4550 - accuracy: 0.7739 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 889/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7739 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 890/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7719 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 891/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7719 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 892/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7739 - val_loss: 0.4437 - val_accuracy: 0.7967\n",
            "Epoch 893/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7780 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 894/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7780 - val_loss: 0.4435 - val_accuracy: 0.8049\n",
            "Epoch 895/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7760 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 896/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7780 - val_loss: 0.4435 - val_accuracy: 0.7967\n",
            "Epoch 897/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7760 - val_loss: 0.4435 - val_accuracy: 0.7967\n",
            "Epoch 898/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4548 - accuracy: 0.7739 - val_loss: 0.4435 - val_accuracy: 0.7967\n",
            "Epoch 899/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7719 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 900/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7739 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 901/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7739 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 902/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7800 - val_loss: 0.4443 - val_accuracy: 0.7967\n",
            "Epoch 903/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7739 - val_loss: 0.4441 - val_accuracy: 0.7967\n",
            "Epoch 904/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4547 - accuracy: 0.7760 - val_loss: 0.4434 - val_accuracy: 0.8049\n",
            "Epoch 905/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4544 - accuracy: 0.7719 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 906/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7699 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 907/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7678 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 908/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7678 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 909/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4546 - accuracy: 0.7719 - val_loss: 0.4429 - val_accuracy: 0.8049\n",
            "Epoch 910/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4545 - accuracy: 0.7760 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 911/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7739 - val_loss: 0.4438 - val_accuracy: 0.7967\n",
            "Epoch 912/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7739 - val_loss: 0.4439 - val_accuracy: 0.7967\n",
            "Epoch 913/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.7780 - val_loss: 0.4440 - val_accuracy: 0.7967\n",
            "Epoch 914/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7719 - val_loss: 0.4440 - val_accuracy: 0.7967\n",
            "Epoch 915/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7780 - val_loss: 0.4449 - val_accuracy: 0.7967\n",
            "Epoch 916/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7719 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 917/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7739 - val_loss: 0.4439 - val_accuracy: 0.7967\n",
            "Epoch 918/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7800 - val_loss: 0.4436 - val_accuracy: 0.7967\n",
            "Epoch 919/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7760 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 920/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7760 - val_loss: 0.4427 - val_accuracy: 0.7967\n",
            "Epoch 921/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7760 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 922/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7760 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 923/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7739 - val_loss: 0.4434 - val_accuracy: 0.7967\n",
            "Epoch 924/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7780 - val_loss: 0.4438 - val_accuracy: 0.7967\n",
            "Epoch 925/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7678 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 926/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4540 - accuracy: 0.7760 - val_loss: 0.4441 - val_accuracy: 0.7967\n",
            "Epoch 927/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4543 - accuracy: 0.7739 - val_loss: 0.4434 - val_accuracy: 0.7967\n",
            "Epoch 928/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4541 - accuracy: 0.7800 - val_loss: 0.4434 - val_accuracy: 0.7967\n",
            "Epoch 929/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7760 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 930/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7780 - val_loss: 0.4437 - val_accuracy: 0.7967\n",
            "Epoch 931/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7780 - val_loss: 0.4433 - val_accuracy: 0.8049\n",
            "Epoch 932/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7780 - val_loss: 0.4446 - val_accuracy: 0.7967\n",
            "Epoch 933/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7699 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 934/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4539 - accuracy: 0.7739 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 935/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7760 - val_loss: 0.4428 - val_accuracy: 0.8049\n",
            "Epoch 936/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7800 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 937/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7780 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 938/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7760 - val_loss: 0.4427 - val_accuracy: 0.7967\n",
            "Epoch 939/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7739 - val_loss: 0.4445 - val_accuracy: 0.7967\n",
            "Epoch 940/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7760 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 941/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7658 - val_loss: 0.4427 - val_accuracy: 0.8049\n",
            "Epoch 942/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7760 - val_loss: 0.4428 - val_accuracy: 0.8049\n",
            "Epoch 943/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7800 - val_loss: 0.4434 - val_accuracy: 0.7967\n",
            "Epoch 944/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7739 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 945/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7800 - val_loss: 0.4434 - val_accuracy: 0.7967\n",
            "Epoch 946/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7800 - val_loss: 0.4433 - val_accuracy: 0.7967\n",
            "Epoch 947/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7719 - val_loss: 0.4441 - val_accuracy: 0.7967\n",
            "Epoch 948/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7800 - val_loss: 0.4433 - val_accuracy: 0.7967\n",
            "Epoch 949/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7739 - val_loss: 0.4427 - val_accuracy: 0.7967\n",
            "Epoch 950/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7719 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 951/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7719 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 952/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7760 - val_loss: 0.4427 - val_accuracy: 0.7967\n",
            "Epoch 953/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4535 - accuracy: 0.7780 - val_loss: 0.4427 - val_accuracy: 0.7967\n",
            "Epoch 954/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4534 - accuracy: 0.7821 - val_loss: 0.4427 - val_accuracy: 0.7967\n",
            "Epoch 955/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4535 - accuracy: 0.7780 - val_loss: 0.4429 - val_accuracy: 0.8049\n",
            "Epoch 956/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7739 - val_loss: 0.4427 - val_accuracy: 0.7967\n",
            "Epoch 957/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7800 - val_loss: 0.4438 - val_accuracy: 0.7967\n",
            "Epoch 958/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7760 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 959/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4533 - accuracy: 0.7739 - val_loss: 0.4432 - val_accuracy: 0.7967\n",
            "Epoch 960/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7739 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 961/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7760 - val_loss: 0.4436 - val_accuracy: 0.7967\n",
            "Epoch 962/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7760 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 963/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4516 - accuracy: 0.7739 - val_loss: 0.4429 - val_accuracy: 0.7967\n",
            "Epoch 964/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4531 - accuracy: 0.7699 - val_loss: 0.4427 - val_accuracy: 0.7967\n",
            "Epoch 965/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7699 - val_loss: 0.4426 - val_accuracy: 0.7967\n",
            "Epoch 966/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7739 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 967/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7780 - val_loss: 0.4436 - val_accuracy: 0.7967\n",
            "Epoch 968/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7800 - val_loss: 0.4432 - val_accuracy: 0.7967\n",
            "Epoch 969/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7699 - val_loss: 0.4443 - val_accuracy: 0.7967\n",
            "Epoch 970/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7739 - val_loss: 0.4427 - val_accuracy: 0.7967\n",
            "Epoch 971/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7780 - val_loss: 0.4432 - val_accuracy: 0.7967\n",
            "Epoch 972/1000\n",
            "123/123 [==============================] - 0s 1ms/step - loss: 0.4530 - accuracy: 0.7800 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 973/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.7739 - val_loss: 0.4435 - val_accuracy: 0.7967\n",
            "Epoch 974/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7800 - val_loss: 0.4431 - val_accuracy: 0.8049\n",
            "Epoch 975/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7760 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 976/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4528 - accuracy: 0.7780 - val_loss: 0.4434 - val_accuracy: 0.7967\n",
            "Epoch 977/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7760 - val_loss: 0.4433 - val_accuracy: 0.7967\n",
            "Epoch 978/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7780 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 979/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.7760 - val_loss: 0.4444 - val_accuracy: 0.7967\n",
            "Epoch 980/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4530 - accuracy: 0.7719 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 981/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7780 - val_loss: 0.4429 - val_accuracy: 0.8049\n",
            "Epoch 982/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7760 - val_loss: 0.4449 - val_accuracy: 0.7967\n",
            "Epoch 983/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7719 - val_loss: 0.4426 - val_accuracy: 0.7967\n",
            "Epoch 984/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7760 - val_loss: 0.4431 - val_accuracy: 0.7967\n",
            "Epoch 985/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4524 - accuracy: 0.7780 - val_loss: 0.4433 - val_accuracy: 0.7967\n",
            "Epoch 986/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7739 - val_loss: 0.4427 - val_accuracy: 0.7967\n",
            "Epoch 987/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7780 - val_loss: 0.4434 - val_accuracy: 0.7967\n",
            "Epoch 988/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7760 - val_loss: 0.4439 - val_accuracy: 0.7967\n",
            "Epoch 989/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4526 - accuracy: 0.7780 - val_loss: 0.4429 - val_accuracy: 0.8049\n",
            "Epoch 990/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4525 - accuracy: 0.7800 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 991/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7719 - val_loss: 0.4429 - val_accuracy: 0.8049\n",
            "Epoch 992/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7760 - val_loss: 0.4432 - val_accuracy: 0.7967\n",
            "Epoch 993/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7780 - val_loss: 0.4432 - val_accuracy: 0.7967\n",
            "Epoch 994/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7780 - val_loss: 0.4437 - val_accuracy: 0.7967\n",
            "Epoch 995/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7760 - val_loss: 0.4437 - val_accuracy: 0.7967\n",
            "Epoch 996/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7780 - val_loss: 0.4428 - val_accuracy: 0.7967\n",
            "Epoch 997/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7719 - val_loss: 0.4430 - val_accuracy: 0.8049\n",
            "Epoch 998/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4522 - accuracy: 0.7678 - val_loss: 0.4433 - val_accuracy: 0.7967\n",
            "Epoch 999/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7821 - val_loss: 0.4433 - val_accuracy: 0.7967\n",
            "Epoch 1000/1000\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4520 - accuracy: 0.7780 - val_loss: 0.4428 - val_accuracy: 0.8049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80o1i3fzZsA-"
      },
      "source": [
        "**11. Plot the training loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "69dOEi6HAiXT",
        "outputId": "2fb5092a-9ad2-4aa5-a79e-b1d5c5e80f5a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deXgUVbbAf4ewhACyo+yLgIgiW4SHiqLPBTfQeaigo7iMKI6O4zbijtuMjj5w3HiDo6KIorggOiiO4q4ocQaUVSIgBFCQXQiQkPP+uFXpSqc76SSddNJ9ft9XX9Vd6ta5Vd333HNXUVUMwzCM1KNWogUwDMMwEoMpAMMwjBTFFIBhGEaKYgrAMAwjRTEFYBiGkaKYAjAMw0hRTAEYhYjIOyIyOt5xE4mIrBaREyshXRWRrt71/4nIHbHELcdzLhCR98orp2GUhNg8gJqNiPwacGYAe4H9nvsKVZ1W9VJVH0RkNfA7VX0/zukq0E1Vs+MVV0Q6AauAOqqaHw85DaMkaidaAKNiqGpD/7qkwk5EaluhYlQX7PdYPbAmoCRFRIaISI6I3CwiPwHPikhTEXlbRDaJyFbvul3gno9E5Hfe9cUi8pmIPOzFXSUip5YzbmcR+UREdorI+yLyhIi8EEXuWGS8V0Q+99J7T0RaBMIvFJEfRWSziNxWwvsZKCI/iUhawO9sEfnWux4gIl+KyDYR2SAij4tI3ShpTRGR+wLum7x71ovIpWFxTxeR/4jIDhFZKyLjA8GfeOdtIvKriAzy323g/qNEZL6IbPfOR8X6bsr4npuJyLNeHraKyMxA2HARWeDl4QcRGer5F2luE5Hx/ncWkU5eU9hlIrIGmOv5z/C+w3bvN3JY4P76IvK/3vfc7v3G6ovIP0XkmrD8fCsiZ0fKqxEdUwDJzUFAM6AjMAb3vZ/13B2AXODxEu4fCCwHWgB/BZ4WESlH3BeBr4HmwHjgwhKeGYuM5wOXAK2AusCNACLSE5jkpd/Ge147IqCqXwG7gBPC0n3Ru94PXOflZxDw38BVJciNJ8NQT56TgG5AeP/DLuAioAlwOjBWRM7ywo71zk1UtaGqfhmWdjPgn8CjXt4mAP8UkeZheSj2biJQ2nueimtSPMxLa6InwwDgeeAmLw/HAqujvY8IHAccCpziud/BvadWwL+BYJPlw0B/4Cjc7/hPQAHwHPBbP5KI9Aba4t6NURZU1Y4kOXB/xBO96yHAPiC9hPh9gK0B90e4JiSAi4HsQFgGoMBBZYmLK1zygYxA+AvACzHmKZKMtwfcVwHvetd3AtMDYQ28d3BilLTvA57xrhvhCueOUeL+EXgj4Fagq3c9BbjPu34GeCAQr3swboR0HwEmetedvLi1A+EXA5951xcCX4fd/yVwcWnvpizvGWiNK2ibRoj3d1/ekn5/nnu8/50DeetSggxNvDiNcQoqF+gdIV46sBXXrwJOUTxZ1f+3ZDjMAkhuNqnqHt8hIhki8nfPpN6Ba3JoEmwGCeMn/0JVd3uXDcsYtw2wJeAHsDaawDHK+FPgendApjbBtFV1F7A52rNwtf3fiEg94DfAv1X1R0+O7l6zyE+eHH/GWQOlUUQG4Mew/A0UkQ+9ppftwJUxpuun/WOY34+42q9PtHdThFLec3vcN9sa4db2wA8xyhuJwncjImki8oDXjLSDkCXRwjvSIz3L+02/DPxWRGoBo3AWi1FGTAEkN+FDvG4ADgEGquoBhJocojXrxIMNQDMRyQj4tS8hfkVk3BBM23tm82iRVXUJrgA9laLNP+CakpbhapkHALeWRwacBRTkRWAW0F5VGwP/F0i3tCF563FNNkE6AOtikCuckt7zWtw3axLhvrXAwVHS3IWz/nwOihAnmMfzgeG4ZrLGOCvBl+EXYE8Jz3oOuADXNLdbw5rLjNgwBZBaNMKZ1du89uS7KvuBXo06CxgvInVFZBBwZiXJ+Cpwhogc43XY3kPpv/EXgWtxBeCMMDl2AL+KSA9gbIwyvAJcLCI9PQUULn8jXO16j9eefn4gbBOu6aVLlLRnA91F5HwRqS0i5wE9gbdjlC1cjojvWVU34Nrmn/Q6i+uIiK8gngYuEZH/FpFaItLWez8AC4CRXvxMYEQMMuzFWWkZOCvLl6EA15w2QUTaeNbCIM9awyvwC4D/xWr/5cYUQGrxCFAfV7uaB7xbRc+9ANeRuhnX7v4y7o8fiXLLqKqLgd/jCvUNuHbinFJuewnXMTlXVX8J+N+IK5x3Ak95MsciwzteHuYC2d45yFXAPSKyE9dn8Urg3t3A/cDn4kYf/VdY2puBM3C19824TtEzwuSOldLe84VAHs4K2ojrA0FVv8Z1Mk8EtgMfE7JK7sDV2LcCd1PUoorE8zgLbB2wxJMjyI3Ad8B8YAvwIEXLrOeBXrg+JaMc2EQwo8oRkZeBZapa6RaIkbyIyEXAGFU9JtGy1FTMAjAqHRE5UkQO9poMhuLafWeWdp9hRMNrXrsKmJxoWWoypgCMquAg3BDFX3Fj2Meq6n8SKpFRYxGRU3D9JT9TejOTUQLWBGQYhpGimAVgGIaRotSoxeBatGihnTp1SrQYhmEYNYpvvvnmF1VtGe5foxRAp06dyMrKSrQYhmEYNQoRCZ9BDlgTkGEYRspiCsAwDCNFMQVgGIaRotSoPoBI5OXlkZOTw549e0qPbCSE9PR02rVrR506dRItimEYAWq8AsjJyaFRo0Z06tSJ6HuVGIlCVdm8eTM5OTl07tw50eIYhhGgxjcB7dmzh+bNm1vhX00REZo3b24WmmFUQ2q8AgCs8K/m2PcxjOpJjW8CMoyEkp0Nq1bBSScVD8vLg6lTYedOyMmBNm3gmmtgxgw47TRo3Bh++QVuvRUOPhiOOw5eegnuvhtWr4bXX4eePWHDBpfewIHQurULb9gQBgxwz69bF44/Ht59F/btgzVrXHrr18Mpp8D338OYMfDll7BgAZx8MtSrB1984WS46CKX/rZtLo2RI6vs9RkJJtF7Upbl6N+/v4azZMmSYn5VyS+//KK9e/fW3r1764EHHqht2rQpdO/du7fEe+fPn6/XXHNNqc8YNGhQvMRNGIn+TpUGuCMSf/5zKNw/LrvMnc8+28U55pjicYYNUz333OL+oJqeHtm/tOORR6KHffWVk+XMM5172bKqeXdGlQFkaYQy1SyACtK8eXMWLFgAwPjx42nYsCE33nhjYXh+fj61a0d+zZmZmWRmZpb6jC+++CI+whpVy88/F/dbvdqd16xx5x8ibK/744/Qtm1xf4Dy9qXs2hU9zE/Tly03t3zPMGocSdEHUN24+OKLufLKKxk4cCB/+tOf+Prrrxk0aBB9+/blqKOOYvny5QB89NFHnHHGGYBTHpdeeilDhgyhS5cuPProo4XpNWzYsDD+kCFDGDFiBD169OCCCy5AvdVcZ8+eTY8ePejfvz9/+MMfCtMNsnr1agYPHky/fv3o169fEcXy4IMP0qtXL3r37s24ceMAyM7O5sQTT6R3797069ePHyIVVoYj3qvqxrsQ3r49epgNz01ZksoC+OMfXRNnPOnTBx55pOz35eTk8MUXX5CWlsaOHTv49NNPqV27Nu+//z633norr732WrF7li1bxocffsjOnTs55JBDGDt2bLGx8//5z39YvHgxbdq04eijj+bzzz8nMzOTK664gk8++YTOnTszatSoiDK1atWKf/3rX6Snp7NixQpGjRpFVlYW77zzDm+++SZfffUVGRkZbNmyBYALLriAcePGcfbZZ7Nnzx4KCgrK/iJShX37XLt6aeTlxZbe7t0VkyeczZujh4VbqHuj7dZpJBtJpQCqE+eccw5paWkAbN++ndGjR7NixQpEhLwohcDpp59OvXr1qFevHq1ateLnn3+mXbt2ReIMGDCg0K9Pnz6sXr2ahg0b0qVLl8Jx9qNGjWLy5OIbJeXl5XH11VezYMEC0tLS+P777wF4//33ueSSS8jIyACgWbNm7Ny5k3Xr1nH22WcDbjKXUQK7d8emAMJr9tEsh1gtgHr1YiuwS1IA4TJYE1DKkFQKoDw19cqiQYMGhdd33HEHxx9/PG+88QarV69myJAhEe+pFyhA0tLSyM/PL1ecaEycOJEDDzyQhQsXUlBQYIV6PMnNhaZNS48XXrOPVnjHagE0b+5G+5RGSQogvEISb+vDqLZYH0AVsH37dtp6nXpTpkyJe/qHHHIIK1euZLXXiffyyy9HlaN169bUqlWLqVOnsn//fgBOOukknn32WXZ7f/wtW7bQqFEj2rVrx8yZbuvevXv3FoYbEYj0biLV7sPjRbpv797Ya+HNm8cWrywKwCyAlCGpLIDqyp/+9CdGjx7Nfffdx+mnnx739OvXr8+TTz7J0KFDadCgAUceeWTEeFdddRX/8z//w/PPP18YF2Do0KEsWLCAzMxM6taty2mnncaf//xnpk6dyhVXXMGdd95JnTp1mDFjBl26dIm7/BViwwY3Jr5RI1eYrlrlasSNGkFamuv8LE8HbUYGFBTEPupm7lz37CD+SJ8g27a588aN8K9/RbYAfvyxeLt8NGJVAEuWRA975x2nBDZtcu5334UDDnDXBQWh91erFtSv795zrVqu+Sktzc1zSE93HWZffw3hE//273fxRNy8g23bXLoHHQRbtrg0d+4sGtcnPR3atXNzGcB9FxGnpAoK3LUqHHGES+/LL92Ip2BYWppLF1yH9/79zr+gAFq1cvGPOgqWL3dhnTpBVhZ07Oi+hf8u0tKgWTNYuxZ+/RX69nX35+e7ePv3u3eyY4d7n82bO7nbtnXzOcD9Rtq2de+6oMDFz8933yczE5YuhSOPdL/b776Do4928zX27YNBg9xvPZ5EGhtaXY/qOA+gurBz505VVS0oKNCxY8fqhAkTEixRUSrtO4Fqt27u+vjjyzdGvroeHTqUHufqqxMvp3/UqpW4Z3fsqPrZZ+W//7XXQtft2sV2z5Ah7nd33XWlx83JUd261V3/7nclx502zc0FAdUzzgj5L11agb+JzQNIap566imee+459u3bR9++fbniiisSLVLVsWKFO3/4YeTwzz4rW3pLlriZswAvvxx9TL5PrVquNhctzK85+rW+8PiNG0OTJs5iSE93tdtataB3b1i0KBTXr41nZLj4mze7WujvfudqsfXquTgDBrg0TzoJXn01slxdusD118PVVzv3Z5/B1q1w5pnOfcop8Mkn0ZuDHn4YAvNdCuXz8d/5JZe473PrrfDnP0d/hw8+CP/7v84yGj8eTjzRXf/mN7E9/8cfQxZMJNmCXH89TJhQ1M+fAwFu1nYsrF3rzu+9V3rcTZtCVsg775Qc95dfQrO/g2l7gzTiSUwKQESGAn8D0oB/qOoDYeEdgOeAJl6ccao62wu7BbgM2A/8QVXnxJKmUTauu+46rrvuukSLUT05+uiyxQ+a2QMHuqaAeNC1a8nhYSO+AFeYR8NfXbV375Cf31QC0K1b0fiHHQaLF7vr/v1h8GB3XauWe0fB5q6DDnJKJpoCKO2d+uHNmzsF0KtXyYqyXz/Xib5xo8vP0UeHCvRYn+/LWppshx1W3K+kPpJ44Q/YUI0tHrimH5/69eMuUqmdwCKSBjwBnAr0BEaJSM+waLcDr6hqX2Ak8KR3b0/PfRgwFHhSRNJiTNMwSqay5iUEa1o1bZKUL69IKB9+f0IwL3l5xf1jGcbqE2vfg09ptddguH9d0j2Rnu93qJcmW6R0K1sB5OWF5CutXyk3t2jB71MJFkAso4AGANmqulJV9wHTgeFhcRTwekpoDPjj0oYD01V1r6quArK99GJJ0zBKprKWmA7WtGqaAgh2Hvv58DtVwxWA7w4qjVhp3LioO9hxG8RPs379ktMPvnP/uqQab6Qht74F0KRJ9PvANbOF401+LBN+IR3Le8vNDclX2iirYNwgibAAgLbA2oA7x/MLMh74rYjkALOBa0q5N5Y0ARCRMSKSJSJZm0oyCY3Uo7KGpQZrWrGOxqku+IW531cAoSaFoALIzw+5y5PH8NpoabXu0gqvSBZArRKKp8A8m0L8QrO0mnKkdMtjAZTl9xcPBVDS+ygn8UpxFDBFVdsBpwFTRSQuaavqZFXNVNXMli1bxiNJI1morPHqNdkCCMrr58PvfAwW9JGagMpCeIEeqUAOUlrhFUwvlgmKkeLs2BFZtliobAWwe3fs8csSt4LEUkivA9oH3O08vyCXAa8AqOqXQDrQooR7Y0mzRnD88cczZ86cIn6PPPIIY8eOjXrPkCFDyMrKAuC0005jmz82PMD48eN5+OGHS3z2zJkzWRIY333nnXfy/vvvl0X8mk3wTxJPZRAsXGqaAvALWpHiBWG4AvApTx7Dm3wq2jwRvD+WJpVIcTZudHsjlKem/MsvZb8nN9f9Bn0FWxLbt5e8IF+QnTurbDJeLG9qPtBNRDqLSF1cp+6ssDhrgP8GEJFDcQpgkxdvpIjUE5HOQDfg6xjTrBGMGjWK6dOnF/GbPn161AXZwpk9ezZNSmuzjEK4Arjnnns48cQTy5VWjST4J4lnB1mwcKlpTUC+vD16uMlwEBotFBwV1LFjqODvGWH8RYcOcOihsT/Xfxa4TWt8/JFPjRq5kUDRaNAADjnEXZe3E37y5KJyRCNS/8G6ctY/GzRwk7dK45JLYt9oZ9q0KrMASv11q2q+iFwNzMEN2XxGVReLyD24yQWzgBuAp0TkOlyH8MXe5IPFIvIKsATIB36vqvsBIqVZCfmrdEaMGMHtt9/Ovn37qFu3LqtXr2b9+vUMHjyYsWPHMn/+fHJzcxkxYgR33313sfs7depEVlYWLVq04P777+e5556jVatWtG/fnv79+wNujP/kyZPZt28fXbt2ZerUqSxYsIBZs2bx8ccfc9999/Haa69x7733csYZZzBixAg++OADbrzxRvLz8znyyCOZNGkS9erVo1OnTowePZq33nqLvLw8ZsyYQY8ePYrItHr1ai688EJ2eWvIP/744xx11FGAWzb6hRdeoFatWpx66qk88MADZGdnc+WVV7Jp0ybS0tKYMWMGBx98cCW/eaLXkh56yP0pmzSB3/++Ys+I1rlZXWnUyI0zP/JIVzg98QQMH+5myJ5xBpx1livszjvPDXd9++2iwyazspzfrbe62a6vveYUiN+PMGNGqCD7+GP497/ds9LSnLtxYxg2LJTepEluLH+vXm63s88+c3K8+SYsW+bmI7Rq5Qr95593aXTqFLr/vffgrbdcmlu3Oj/fQps3z+Xhs89cgblvn5sRDPDVVy7+2rXu6NABWrRw8wUGD3YzchcvduP/DzzQ7cvQrJlToBs2uNr6QQe5vG/Y4GYDr1vn+lYWL3bvb9my0Hvx5xGkpzuLoH17Z4n06AHvv+/S8uN17OjS9EddqTql6XfM5+W593nwwW5Y7+rV7nmVQaTZYdX1KHUm8LXXqh53XHyPa68t9sxwTj/9dJ05c6aqqv7lL3/RG264QVVVN2/erKqq+fn5etxxx+nChQtVVfW4447T+fPnq6pqx44dddOmTZqVlaWHH3647tq1S7dv364HH3ywPvTQQ6rqdh3zue222/TRRx9VVdXRo0frjBkzCsN8d25urrZr106XL1+uqqoXXnihTpw4sfB5/v1PPPGEXnbZZcXys2vXLs3NzVVV1e+//1799z579mwdNGiQ7tq1q0j+BgwYoK+//rqqqubm5haGB6mUmcDvv198FuWpp8YnbT89w0gCiDIT2BaDiwPBZqBg888rr7xCv3796Nu3L4sXLy7SXBPOp59+ytlnn01GRgYHHHAAwwK1qEWLFjF48GB69erFtGnTWLy4ZGNp+fLldO7cme7duwMwevRoPvnkk8Lw33izK/v371+4gFyQvLw8Lr/8cnr16sU555xTKHesy0ZnVMJ45YjYomWGUSFqWANnKSRoPejhw4dz3XXX8e9//5vdu3fTv39/Vq1axcMPP8z8+fNp2rQpF198MXvKOW794osvZubMmfTu3ZspU6bw0UcfVUhef0npaMtJ15hlo211UsOoEGYBxIGGDRty/PHHc+mllxbW/nfs2EGDBg1o3LgxP//8M++Usv7Hsccey8yZM8nNzWXnzp289dZbhWE7d+6kdevW5OXlMW3atEL/Ro0asdNfRTHAIYccwurVq8nOzgZg6tSpHHfccTHnp8YsGx20AOK9SqJhpACmAOLEqFGjWLhwYaEC6N27N3379qVHjx6cf/75HF3K+iT9+vXjvPPOo3fv3px66qlFlnS+9957GThwIEcffXSRDtuRI0fy0EMP0bdv3yL79aanp/Pss89yzjnn0KtXL2rVqsWVV14Zc16uuuoqnnvuOXr37s2yZcuKLBs9bNgwMjMz6dOnT+Ew1alTp/Loo49yxBFHcNRRR/HTTz/F/KwKEVQ0lTBL0jCSHdHSFiaqRmRmZqo/ft5n6dKlHFqW4WpGQqiU7zRhAtxwg7v2124/9VSYPbviaftDQWvQ/8MwoiEi36hqZri/WQBGzSQvL1T4Q6gJqG7diNFV4dNP3XnlSjcycMMGN0LP7wdft86NBoyVefMir9llGDWF5OoENlKHb74JXQ8f7tZ/f+01+NOfIkZ/9VU491x4+mm47DLn528YBe7sr8asCsyZU3SN+DCWLXMbNF1zDTz6aMWzYxiJICkUgKoiZVnJ0KhSKr2Z0euA5phjUIWFC9wcm2CL03ffufPawBKEQbGWLSsat+DAk2l5OGz4xi2d/8svbr+Wdu3cvKWff3ZxFyyILNLSpW7ibfhE4k2b3Nyh4GTZ0li92s1R8ncmjMSePS5v4VsAGNHJzoY2bSplleUaQ41vAkpPT2fz5s2VX8gY5UJV2bx5c5UNJZ00yW2S1bOn6xLw8QdLRRssFFQWRxzhtrdt29Zt07pjB7Rs6RTBgQe6OP7yL5EmCq9a5Z5/663Fw1q1coVOWejc2e2XUhIXXgjdu9vUiFgpKHDKcsSIREuSWGq8BdCuXTtycnKwpaKrL+np6bSLtNtVRYjS+L5oUej6p59CfcMffOD8fEugLITfs2ZNaPn47GxXq/cXqt21K7Tplj/3bts219wUrMHPm+dWR2jQwC1E+fPPTjkddJCzNmrVcitZ+HqztL4Jfz3CfftsQFQs+FNyStudMdmp8QqgTp06dPYXuzJShyhV3WAhm5fnlrMJLi3z3HNlf9QxxxR1B3eIzMlxtXrfAD32WLc8TpCmTV2h/NBDIb9Bg1yfxMsvuyVqfPr2hf/8x12feCL861+xyRjsyzBKxywlR41vAjJSlCiTzYIr865cWbwwriy2bnWWQPB527aFLIXcXAhbNJYZM5yCCuIX/uBGKEUydCKsHl5IhIndRgRimauYmxvfTedUS/520di3r/ImvZsCMGomEapwH3wAwS0URo+GMkyArhDNmjlLIMjy5UU3ylq/vmi4aumrF4cvAjlnjrMooq0GElzm34hOLBZAw4Zl66wvjb//3X07b4J+zAwaVPp+O+XFFIBR83jtNfi//yt05ue7wvSVV6LfEj4ResaMou7gfujvvRcHGSOwcWPZ7/EHOPn4TUKffw5797rOTAg1/ZgFEBux1KgLCorX2CPt/RL0868LCkLHtm2uFv/66y4suH1Afn7oCMf3q0wr1hSAUfMYMcLN6gKe5lLq1IG//tXtBxKN4AZtgwe7ZfEhtN+IryAGDYKTTqoEmSne3FMe/Br+7be7DuI+fZzbFEDZKE8fwLffumG9wY7jN95wfsuXOwu0dm23pUKjRnDCCW4EV9OmroLhK+9hw9xv4aef3O/PP+bNC6X7+OPOL7hRma/s44kpAKNmEejl/IAT+B1PA3DnnSXfFhwfP2tW6I+6fr374z74oNtDxF9FYu1aeOaZ0D2ff160Nh4c4jlhQnkzUzby8lytP0j4CCVTALFRljb1/ftd4fvFF8795puhsNdec+evvoJ333XXs2e79D/+2I0Yi8TGjTB/flG/oOX5wAPuHFxWqzz9B6USaZOA6npE2hDGSB3WrFGtw97CzVpmcUax/WCiHapl3+Pl229D93h73xS6N20qmt7RR8cmR6TjxBNji1evnurZZ0fOW/367nrBAnd++OFQPiZMcH5nn63avHnI/9dfnf+TTxbP+7Bhqq1bx/6uqpr1653sr75avvvffLPo+9u3z117ezCpaij84IPd+dBD3fmKK4qGg2r79mX75t98o/rEE2W75/vvy/++qMiGMCIyVESWi0i2iIyLED5RRBZ4x/ciss3zPz7gv0BE9ojIWV7YFBFZFQjrE1fNZiQd33wD9QnZ7rmUPOB9/Hh3BE3rshDcwjZ8bH34vLZZs+Duu0M1t1q1ivZJPPoo3HFHyP2Xv4Suo9XsXnqp6BDUvXuLroDhExwp5E+HCaZ/773u/MYbbs6Bz4YN7vzXvxZPc9asUHh1xJ+5/dhj5bvfX+XD3x7Ynyh4003F4/pzMEra+jc4wzwWNm8ue42+nFuHl0wkrRA8cHv2/gB0AeoCC4GeJcS/BrfHb7h/M2ALkOG5pwAjSnt+8DALILV54w3Vg1hfWCV6ltGl1vqDlGeXx3bt3D0FBUXT8GuM4ent2uX8Dj+8+DP37HHXhx2mun17KKxPn6Jy+8/85BPVp58uvWZ4zjnF/Q46KCRT06aR38vSpc7dpUt83lVJ+NZUWXYG/emnkBy1a6s2aqT63nuqubnF87tmjer48aqdOrl7//Y31Q4dQt8tnKuvdvd17OjcOTlF0xs/vuR3/pvflK32Hs2iizXuUUdV6PVHtQBimQg2AMhW1ZUAIjIdGI7b6D0So4C7IviPAN5RVdvGySg3sVoAn31W3O+dd6Br17I974svXK07fKmp2rVdP3T4MM6MDDfCyN/+YcGCUE2vXj23KN1RRxW1KIIdks8/DwMGuHbmgQNdOg88ACtWRJcxfEQThDq3S8LvlK5VBT2BU6e686xZRZfdKImg5Zaf72rpn30Ghx9ePO7cuc7aA1dkXnutu960qfjwXAit5eS/+/BOYT+taPgjeipCeH9OSVTaHkuRtELwwBXc/wi4LwQejxK3I7ABSIsQNhc4I+CeAiwHvrZ9rG8AACAASURBVAUmAvWipDkGyAKyOnToUDE1aNRo3nhD9TC+K6wWPcz1Mdf+40U80/fTGjiw5HTvuaf8tczjjy9uAZx7rurtt6vOnevc3burnnSS6mOPhdrW/WPMmJAc06c7vzZtVBcvdpbDp5+GwleuVO3cWfW555z7wQdVa9Vy1sjo0aE0R48OtZn7/RP9+6secYTqyJGun2LSJFeDj5SnH38sOc9+m71/HHigk/n000OynnBCKLx//8h9K8Fj8OCK1/hLOw44IHpY9+4V/a1FtgDirQBuBh6L4N8a2ATUCfMToB7wHHBnabJYE1CSs3696ksvuePVV9152jTVr79Wfecd/fz6V/VvXFP4r7iX26pcASxdqvrii/FJa+pU1RtucM0PL7+sumhR5Hi33urydOmlqkOHqr79dtkKlnAF4B+zZrnzIYeE/J58Mvq79DuafSUCqkceGQp/6y3n162bcwfT8DtQYz3OOy962MKF5S9kfXr3jhw+YEBk/9KU8Pnnu3OtWiXHGztW9corVdPSivq/9JJqixYh9/XXFw1v375iv7WKKIBBwJyA+xbglihx/wMcFcH/WmByCc8YArxdmiymAJKcYcPK9G++iserXAEkghtucHl68EHn3rat/AVg8Lj77tjj9uoVPSxaYVodjyFDVO+6K9TPEn7MnesskHD/jz4qOd0XXnDnCy4I+QWv/eODD9w3vOuu4r/Xww4LuZcsKRoeHL1VHqIpgFha/+YD3USks4jUBUYCs8IjiUgPoCnwZYQ0RgEvhcVv7Z0FOAtYFOE+I5UIDlE5/vhiwa9wDgBL6cGhLGESodldLwV+XZMmVZqECcFvK/ZHHpW0L0BZuOuu2OOWtIrqwoUVl6W8DBxYtvgffeRGa4Uvy+Gzf3/RnyG4OSLHHOPmmgTnglx9NfTu7eaT+JO0IvWn3H67W/hv7NiQvMElQnzefhsuuMCNGOvRA+67LzS3oLIWrytVAahqPnA1MAdYCryiqotF5B4RGRaIOhKY7mmbQkSkE9Ae+Dgs6Wki8h3wHdACuK+8mTCShMBPZ3d6s2LBK+hWeF7Gofj1lx49YOTIULzwZR9qOv5r8TuOgx3Sl14aWxpbtrjdy5KN4GS9shCcVevvEAfFF9/r08dtMpeW5hRHcG2pE05wnfz9+5esAA45xK36+uSToTV9IimATp3ghRfcdxKB226Dww5zYZXVCRzTctCqOhuYHeZ3Z5h7fJR7VwNtI/ifEKuQRooQWHpx6TLoHxa8GfevqZ8O6YHojzzizpMnh7Z1TCbuucedL7ww5Dd9uhsZc8opbnTRzp2u8IhGRoYrUF5+ObQmUa9e5dsfoTpRr57L0/nnuxnZ/uifc8+FIUPcDO5p04rec8opbvTWTTe593jBBW6rUHDLgMyd69bf+flnGDOm6L3BsfjBQjyoAF580Z3feiu63EOGOBkPPNBdR6Nx4xIyHw8itQtV18P6AJKcHj0KGz2/O+R/ijWgXswz7vrMM7V7d3c5aVKiha4e+B2wp58euY06OB6+dm3nt2uXakZG0XjTppXejh7tGf7RtWvpaWRkqB57bMlxMjNLf+6aNaF85eUVbVP3Cca/+ebi786fER1+XzT8uMFOe3++xqWXhvx++1st7B8oLwUFZZMtGlRkJrBhVAmBhs5I49h3EVoT98YbnTk+eHBVCFb9OfFEV5OdNAmeesr5ff55KDzYbPTJJ66mnJFRdD/c888PLZIXJDjuftIkt1AZuCaRkSPdJjY+554bfYx8MF7z5iE5wW1n6eNvsxmciXzeefDss6GZuz5164aua9d2v4u5c4vGefxxt0z4yJGuOSecBg2cv79rXGlMmQLDhxedUzJypHt/998fWxqxIgLjxsGHH8Y33UIiaYXqepgFkHzMmuXGpLdsqbq5dsvC6s6iHsUtgOG8UWgBGLFRWu2xdevicXy3Pw5/5crS0/GHiG7f7tz++H7/OPhg1eXLQ+7evYs+6/TT3fpFEBqWGhwqGWTIkJD/zz+X771UBfGwAOIFFZgJbBiVxrDAMII6gVm+kVa1PDITNyXQiBuqxf3GjnWzkbt1c7OQ27d3HZgl7Wfw9ttuXR5/ZvRFF7nNaw491PXRTJsGBx8Mp53mZvg+/3zR+x9+GHbsgCOOgMsvd3FGj3Z7LPsrbvo89pjrnD3uuMidqdWFu+6CVavgjDMSLUl0RCP9AqopmZmZmpVlJUAyEWyayKM2tXE7atzPrdzGn4tG/vxztzbCTTdFXsHMKIb/fqP9zQ86KLQsQiKKgtLkM+KDiHyjqpnh/mYBGNUCoYDa7OdFRnEn9/AjHVlPGwTlwjEZDLywu1tEZ86ckodNGEW44w5XC43GP/4BZ55ZtjkB8eTKK4uvtGpUHWYBGAnFrwHWZS97SedW7ucv3Fokzscfw7HHJkA4w0gSolkANgrIqBbUxjX654cZpY0aFR09YhhG/LAmICNhBJc4roPb7DaPouM/d+yoSokMI7UwC8BIGMGx35EUwM03V7VEhpFamAIwEs748bBpvWsC8hXAokWh7RUNw6gcTAEYCadBAyDPWQB+H0CXLgkUyDBSBFMARtWSlwcnnMD+rt1RhDcZ5pY39hTAP6bUoaDAhgYaRlVgCsCoWjZuhA8/ZN0aN+FrGG9Rrx6FU3+lbp1i++8ahlE5mAIwqhZvwbdX84YXetWrR6EFENNu5oZhxAVTAEbV4u1s4a/tD96mF74CqG0jkw2jqohJAYjIUBFZLiLZIjIuQvhEEVngHd+LyLZA2P5A2KyAf2cR+cpL82Vvu0kj2fEsgKAC6HW4mgVgGAmgVAUgImnAE8CpQE9glIj0DMZR1etUtY+q9gEeA4Irguf6Yaoa3ELyQWCiqnYFtgKBjdmMpCWCBcC+faHlP00BGEaVEYsFMADIVtWVqroPmA4MLyF+sQ3gw/E2gj8BeNXzeg63MbyR5ORtdwqgebeAAsjNNQvAMBJALAqgLbA24M4hwh6/ACLSEegMBPfkSReRLBGZJyJ+Id8c2KZuw/nS0hzj3Z+1adOmGMQ1qjPjrnVNQG16RVEA1gdgGFVGvP9tI4FXVXV/wK+jqq4TkS7AXBH5Dtgea4KqOhmYDG410LhKa1Qt8+Zx5hq3n6A2aBjy/8MfQov+mAVgGFVGLBbAOqB9wN3O84vESMKaf1R1nXdeCXwE9AU2A01ExFdAJaVpJAnr757MYD5lPpn8mNfG7UYC8NVXsHSp23z24IMTK6RhpBCxWADzgW4i0hlXSI8Ezg+PJCI9gKbAlwG/psBuVd0rIi2Ao4G/qqqKyIfACFyfwmjgzYpmxqjebF67m510ZQDzGbabort+G4ZR5ZRqAXjt9FcDc4ClwCuqulhE7hGR4KiekcB0LbrDzKFAlogsBD4EHlDVJV7YzcD1IpKN6xN4uuLZMaozB9TezW4yAPj11wQLYxhGbH0AqjobmB3md2eYe3yE+74AekVJcyVuhJGRItTJzyUXt8jPrl0JFsYwDJsJbFQdtfaELIAWLRIsjGEYpgCMqiNtby67yWDCBJgyJdHSGIZhg66NKiNt725yqc9ll+GWgDYMI6GYBWBUDf/8J+m7fmE3GdS1VZ8Mo1pgFoBR+eTkwBlnkAGsoYMpAMOoJpgFYFQ+29zisG8OncR9aeOpZb86w6gW2F/RqHz8JaDrt6NuPdvuyzCqC6YAjMrHWwJ6Nxlu9y/DMKoFpgCMysdTALvUOoANozphCsCofLwmoJ+216dZswTLYhhGIaYAjErnp5XOAnj7wwwOOSTBwhiGUYgpAKPyKCiA7GxWfPAjALnUp0+fBMtkGEYhNg/AqDzuvx/uvJPBQAHCDg5g7NhEC2UYho9ZAEblkZMDTZrwwtAXOIG59DvuAFq2TLRQhmH4mAVgVB67d7OzTlMufPcCAPSjxIpjGEZRzAIwKo/cXH7clJFoKQzDiEJMCkBEhorIchHJFpFxEcInisgC7/heRLZ5/n1E5EsRWSwi34rIeYF7pojIqsB91j2YZOiu3YUbwBiGUf0otQlIRNKAJ4CTgBxgvojMCmztiKpeF4h/DW7jd4DdwEWqukJE2gDfiMgcVd3mhd+kqq/GKS9GNaNgV27hBjDHHptgYQzDKEYsFsAAIFtVV6rqPtwm7sNLiD8KeAlAVb9X1RXe9XpgI2DdgEnOvHlu/bedPzsL4LHH4OOPEy2VYRjhxKIA2gJrA+4cz68YItIR6AzMjRA2AKgL/BDwvt9rGpooIhFXiRGRMSKSJSJZmzZtikFcI5Hs3w+DBsHJJ8Oa750FUN9agQyjWhLvTuCRwKuquj/oKSKtganAJapa4HnfAvQAjgSaATdHSlBVJ6tqpqpmtrQxhNWevXvdef58yMBZALVtrJlhVEtiUQDrgPYBdzvPLxIj8Zp/fETkAOCfwG2qOs/3V9UN6tgLPItrajJqOL4CAKiPswC8pYAMw6hmxKIA5gPdRKSziNTFFfKzwiOJSA+gKfBlwK8u8AbwfHhnr2cVICICnAUsKm8mjOrDnj2ha98C8BYDNQyjmlGqca6q+SJyNTAHSAOeUdXFInIPkKWqvjIYCUxXVQ3cfi5wLNBcRC72/C5W1QXANBFpCQiwALgyLjkyEkokCyDziMTJYxhGdGJqnVXV2cDsML87w9zjI9z3AvBClDRPiFlKo0awYwds2OCu77t7P+l37WXsdfVpfGJi5TIMIzLWPWfEjcaNQ9dHdHdtQY1b20xgw6iu2FIQRqVQH6/n18aAGka1xRSAUSnU2uP1/GaYBWAY1RVrAjLiyvHM5SqepOcjvzoPswAMo9piFoARV0bzHMOYRcNtOZCZCf37J1okwzCiYBaAERfy8925PrlsbNSVtqsWuQG+hmFUW8wCMOKCP9s3g900bFUfscLfMKo9pgCMuODP9q1PLnUOsI5fw6gJmAIw4kLQAkhvZh2/hlETMAVgxIWtW925TZNc0hqaBWAYNQFTAEaFGTIE+vVz1y0b7rax/4ZRQ7BRQEaFKChwu301ZQsjmU69HZts7L9h1BBMARgVwu/8vYBpPMYfYAfQrVtCZTIMIzZMARgVYudOd87AaQJdtx5p0zqBEhmGESvWB2CUmwcfhDZt3HVt3EwwadkigRIZhlEWTAEY5WbcuNB1HfLchW0AbBg1BlMARrl4442i7jrkoWlp2BRgw6g5xKQARGSoiCwXkWwRGRchfKKILPCO70VkWyBstIis8I7RAf/+IvKdl+aj3t7ARg3hN78p6h6UmY/UqZMYYQzDKBelKgARSQOeAE4FegKjRKRnMI6qXqeqfVS1D/AY8Lp3bzPgLmAgMAC4S0SaerdNAi4HunnH0LjkyKhUfv0VRo0q6rd1K5wwOA9MARhGjSIWC2AAkK2qK1V1HzAdGF5C/FHAS971KcC/VHWLqm4F/gUMFZHWwAGqOs/bRP554Kxy58KoMj7+GKZPB6GAw1hE2ya7aLznZ1ixwtr/DaOGEcs/ti2wNuDOwdXoiyEiHYHOwNwS7m3rHTkR/COlOQYYA9ChQ4cYxDUqk3/8w53P5RWmMwqOGw5tZoFqYgUzDKPMxLsTeCTwqqruj1eCqjpZVTNVNbNly5bxStYoJwsWuPNB/OQuVq2ywt8waiixKIB1QPuAu53nF4mRhJp/Srp3nXcdS5pGNWLLFvjDH+CRP3vLf+7Zk1iBDMMoN7EogPlANxHpLCJ1cYX8rPBIItIDaAp8GfCeA5wsIk29zt+TgTmqugHYISL/5Y3+uQh4s4J5MSqZvDzYsQOaNye0BsSvvyZUJsMwyk+pCkBV84GrcYX5UuAVVV0sIveIyLBA1JHAdK9T1793C3AvTonMB+7x/ACuAv4BZAM/AO/EIT9GJfKSZ9s1b05oA4AtW6LGNwyjehPTsA1VnQ3MDvO7M8w9Psq9zwDPRPDPAg6PVVAjsWzcCKO9WRytWgGLPQvAmoAMo8ZiM4GNmHjvvdB1t26ELADDMGospgCMUsnLgwsvDLm7diXUB2AYRo3FZu4YUdmwwU38WrWqqH/DhkS2AGpZfcIwahKmAIyo+Es9R2T3bhfhoovcFpCNGkHv3lUmm2EYFccUgBEz8+bBEUd4jtxcOPRQ+MtfEiqTYRjlx2x2IyLBFh5/ndaBAwPb/e62zd8No6ZjCsAoRl4efPppyP3ZZ/DTT2GRcnNt83fDqOGYAjCKMXIknHJKyN2hAxx4YFgkswAMo8ZjCsAoxuuvu3PjxrB4MbRrFyGSWQCGUeMxBWBEZfBg6NkzSqBZAIZR4zEFYESlefMoAf/8p1MAZgEYRo3GFIBRhIceCl337Rslkr8qXLCjwDCMGocpAKMI48aFrq+5Jkqk3Fw47DA45pgqkckwjMrBFIBRyN69UFDgrk8/vYSVHawD2DCSAlMARiEbNoSu/clfEbEOYMNICkwBGIVccUXouti4/yBmARhGUhCTAhCRoSKyXESyRWRclDjnisgSEVksIi96fseLyILAsUdEzvLCpojIqkBYn/hlyygP/pr/I0fChAklRDQLwDCSglIXgxORNOAJ4CQgB5gvIrNUdUkgTjfgFuBoVd0qIq0AVPVDoI8Xpxlu+8fA1iLcpKqvxiszRny47jo44IASIpgFYBhJQSwWwAAgW1VXquo+YDowPCzO5cATqroVQFU3RkhnBPCOqtpOItUQf2fH+vUhM7OEiHl58MMPZgEYRhIQiwJoC6wNuHM8vyDdge4i8rmIzBORoRHSGQm8FOZ3v4h8KyITRaRepIeLyBgRyRKRrE2bNsUgrlEe/L3dJ0woZV+Xr79257p1K10mwzAql3h1AtcGugFDgFHAUyLSxA8UkdZAL2BO4J5bgB7AkUAz4OZICavqZFXNVNXMli1bxklcI5zNm9056uxfn19/decLLqhUeQzDqHxiUQDrgPYBdzvPL0gOMEtV81R1FfA9TiH4nAu8oap5voeqblDHXuBZXFOTUQX8+99ukpdqyC9mBeBvFGB9AIZR44lFAcwHuolIZxGpi2vKmRUWZyau9o+ItMA1Ca0MhI8irPnHswoQEQHOAhaVQ36jHBx7LDz+OPzyS8hvzRp3bhveuBeOvxm89QEYRo2n1FFAqpovIlfjmm/SgGdUdbGI3ANkqeosL+xkEVkC7MeN7tkMICKdcBbEx2FJTxORloAAC4Ar45MlozR27XLnY4+F7t3d9YoVkJYGnTuXcrNZAIaRNMS0J7CqzgZmh/ndGbhW4HrvCL93NcU7jVHVE8ooqxFnli2D9HR3Xa8eXH55DH27ZgEYRtKQEpvCT5gACxcmWoqqo1YtN5a/cAP3AD/+GLo+4QT44IMyJm4WgGEkDSmhABYtgk8+SbQUVceaNdCwITz2WPEwf7cvgIkTy5H4Dz+4sykAw6jxpIQCeOaZREtQtfTvD++8A3/8Y/GwTz6Bpk1D4/7LzJtvunOJkwUMw6gJpIQCSDWGDXO1+ylTIoeffXYFEq9bF4YMqUAChmFUF0wBJCF33eWOSmHPHujRo5ISNwyjKjE73igbthCcYSQNpgCM2FG1paANI4kwBWDETl6e2zPSLADDSApMARixY5PADCOpMAVgxI6vAMwCMIykwBSAETu//707N2yYWDkMw4gLpgCM2NmwwZ3PPDOxchiGERdMARixs3s3nHUWNG6caEkMw4gDpgCM2LE5AIaRVJgCMGLH5gAYRlJhCsCIHbMADCOpiEkBiMhQEVkuItkiMi5KnHNFZImILBaRFwP++0VkgXfMCvh3FpGvvDRf9rabNKozZgEYRlJRqgIQkTTgCeBUoCcwSkR6hsXpBtwCHK2qhwHBhYhzVbWPdwwL+D8ITFTVrsBW4LKKZcWoVAoKYO9eswAMI4mIZTXQAUC2qq4EEJHpwHBgSSDO5cATqroVQFU3lpSgtxH8CcD5ntdzwHhgUlmEN+LMmDHw3XeRwwoK3NkUgGEkDbE0AbUF1gbcORTf47c70F1EPheReSIyNBCWLiJZnv9Znl9zYJuq5peQJgAiMsa7P2vTpk0xiGuUi4ICeOop2LQJDjig+NGkCZx2Gpx6aqIlNQwjTsRrP4DaQDdgCNAO+EREeqnqNqCjqq4TkS7AXBH5Dtgea8KqOhmYDJCZmalxktcIZ88ed778crj55sTKYhhGlRCLBbAOaB9wt/P8guQAs1Q1T1VXAd/jFAKqus47rwQ+AvoCm4EmIlK7hDSNqsQ2ezeMlCMWBTAf6OaN2qkLjARmhcWZiav9IyItcE1CK0WkqYjUC/gfDSxRVQU+BEZ4948G3qxgXoyKYArAMFKOUhWA105/NTAHWAq8oqqLReQeEfFH9cwBNovIElzBfpOqbgYOBbJEZKHn/4Cq+p3HNwPXi0g2rk/g6XhmzCgjttSzYaQcMfUBqOpsYHaY352BawWu945gnC+AXlHSXIkbYWRUB8wCMIyUw2YCGw6zAAwj5YjXKCCjJvHBB/Duu0X91nojfc0CMIyUwRRAKnLHHfDVV5CeXtT/oIOga9fEyGQYRpVjCiAV2bXLbeoyc2aiJTEMI4FYH0AqYou6GYaBKYDUxJZ1NgwDUwCpiVkAhmFgCiA1MQvAMAxMAaQeBQVu4TezAAwj5bFRQKnE/v3w3nvu2iwAw0h5zAJIJT76yK3pD27Mv2EYKY1ZAKnEli3u/MYbMGxYyXENw0h6zAJIJfwF3444AmrZpzeMVMdKgVTCX/DN2v8Nw8AUQGphSz4bhhHAFEAqYUs+G4YRwBRAKpGb69r+69RJtCSGYVQDYhoFJCJDgb8BacA/VPWBCHHOBcYDCixU1fNFpA8wCTgA2A/cr6ove/GnAMcB270kLlbVBRXKTUns2AH5+ZWWfI1gyxZX+xdJtCSGYVQDSlUAIpIGPAGcBOQA80VkVmBvX0SkG3ALcLSqbhWRVl7QbuAiVV0hIm2Ab0Rkjqpu88JvUtVX45mhiLz9tlv+2IDWrRMtgWEY1YRYLIABQLa3hy8iMh0YDiwJxLkceEJVtwKo6kbv/L0fQVXXi8hGoCWwjaokO9udH3jAOkCPOCLREhiGUU2IRQG0BdYG3DnAwLA43QFE5HNcM9F4VS2y56CIDADqAj8EvO8XkTuBD4Bxqro3/OEiMgYYA9ChQ4cYxI2AP/rl2muL74JlGIaRosSrE7g20A0YAowCnhKRJn6giLQGpgKXqGqB530L0AM4EmgG3BwpYVWdrKqZqprZsmXL8km3e7dr965Xr3z3G4ZhJCGxKIB1QPuAu53nFyQHmKWqeaq6CvgepxAQkQOAfwK3qeo8/wZV3aCOvcCzuKamysFf/tg6Pw3DMAqJRQHMB7qJSGcRqQuMBGaFxZmJq/0jIi1wTUIrvfhvAM+Hd/Z6VgEiIsBZwKIK5KNkbAMUwzCMYpTaB6Cq+SJyNTAH177/jKouFpF7gCxVneWFnSwiS3DDPW9S1c0i8lvgWKC5iFzsJekP95wmIi0BARYAV8Y7c4XYBiiGYRjFEFVNtAwxk5mZqVlZWWW/8bzzYOFCWLYs/kIZhmFUc0TkG1XNDPdPjZnAZgEYhmEUIzX2Axg0CHr2TLQUhmEY1YrUUAC33JJoCQzDMKodqdEEZBiGYRTDFIBhGEaKYgrAMAwjRTEFYBiGkaKYAjAMw0hRTAEYhmGkKKYADMMwUhRTAIZhGClKjVoLSEQ2AT+W8/YWwC9xFKcmYHlODSzPqUFF8txRVYttqFKjFEBFEJGsSIshJTOW59TA8pwaVEaerQnIMAwjRTEFYBiGkaKkkgKYnGgBEoDlOTWwPKcGcc9zyvQBGIZhGEVJJQvAMAzDCGAKwDAMI0VJCQUgIkNFZLmIZIvIuETLEw9EpL2IfCgiS0RksYhc6/k3E5F/icgK79zU8xcRedR7B9+KSL/E5qD8iEiaiPxHRN723J1F5Csvby+LSF3Pv57nzvbCOyVS7vIiIk1E5FURWSYiS0VkULJ/ZxG5zvtdLxKRl0QkPdm+s4g8IyIbRWRRwK/M31VERnvxV4jI6LLIkPQKQETSgCeAU4GewCgRSYb9IfOBG1S1J/BfwO+9fI0DPlDVbsAHnhtc/rt5xxhgUtWLHDeuBZYG3A8CE1W1K7AVuMzzvwzY6vlP9OLVRP4GvKuqPYDeuLwn7XcWkbbAH4BMVT0cSANGknzfeQowNMyvTN9VRJoBdwEDgQHAXb7SiAlVTeoDGATMCbhvAW5JtFyVkM83gZOA5UBrz681sNy7/jswKhC/MF5NOoB23h/jBOBtQHCzI2uHf29gDjDIu67txZNE56GM+W0MrAqXO5m/M9AWWAs0877b28ApyfidgU7AovJ+V2AU8PeAf5F4pR1JbwEQ+jH55Hh+SYNn8vYFvgIOVNUNXtBPwIHedbK8h0eAPwEFnrs5sE1V8z13MF+FefbCt3vxaxKdgU3As16z1z9EpAFJ/J1VdR3wMLAG2ID7bt+Q3N/Zp6zftULfOxUUQFIjIg2B14A/quqOYJi6KkHSjPMVkTOAjar6TaJlqUJqA/2ASaraF9hFqFkASMrv3BQYjlN+bYAGFG8qSXqq4rumggJYB7QPuNt5fjUeEamDK/ynqerrnvfPItLaC28NbPT8k+E9HA0ME5HVwHRcM9DfgCYiUtuLE8xXYZ698MbA5qoUOA7kADmq+pXnfhWnEJL5O58IrFLVTaqaB7yO+/bJ/J19yvpdK/S9U0EBzAe6eSMI6uI6k2YlWKYKIyICPA0sVdUJgaBZgD8SYDSub8D3v8gbTfBfwPaAqVkjUNVbVLWdqnbCfce5qnoB8CEwwosWnmf/XYzw4teomrKq/gSsFZFDPK//BpaQxN8Z1/TzXyKS4f3O/Twn7XcOUNbvOgc4WUSaepbTyZ5fbCS6E6SKOlpOA74HfgBuS7Q8ccrTMTjz8FtggXechmv7/ABYAbwPNPPiC2401A/Ad7gRFgnPRwXyPwR427vuAnwN1SUjDQAAAIBJREFUZAMzgHqef7rnzvbCuyRa7nLmtQ+Q5X3rmUDTZP/OwN3AMmARMBWol2zfGXgJ18eRh7P0LivPdwUu9fKeDVxSFhlsKQjDMIwUJRWagAzDMIwImAIwDMNIUUwBGIZhpCimAAzDMFIUUwCGYRgpiikAwzCMFMUUgGEYRory/31pS5AIh7OFAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8fUXoqeZvwf"
      },
      "source": [
        "**12. Evaluate the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawHhkURYMLE",
        "outputId": "c0ada607-1f24-4171-cc90-c05d038cb976"
      },
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 0s 1ms/step - loss: 0.5336 - accuracy: 0.7229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WCSw36oZyG_"
      },
      "source": [
        "**13. Predict on new datatset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE27mGFYo3G",
        "outputId": "0c3aefb0-7c62-4a7b-e51e-31e574e6630d"
      },
      "source": [
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5559551, 0.4440449]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RDC-ZHYqv_",
        "outputId": "37bfaf93-01c4-4dc7-8cc8-340ca70f52d4"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mMqJtXYz2Q"
      },
      "source": [
        "**Reference:** - https://keras.io/"
      ]
    }
  ]
}